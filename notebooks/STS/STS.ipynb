{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d7c8bf",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c899d1",
   "metadata": {},
   "source": [
    "### Please download and extract STS dataset from here: https://gluebenchmark.com/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa35cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:11:21.514049Z",
     "start_time": "2021-11-03T09:11:21.497146Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca967a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:12:33.718379Z",
     "start_time": "2021-11-03T09:12:33.711128Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import networkx as nx\n",
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569936e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:11:34.004171Z",
     "start_time": "2021-11-03T09:11:33.583683Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from graphUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4cfbe26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:12:20.897465Z",
     "start_time": "2021-11-03T09:12:20.390830Z"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth = {}\n",
    "first = set()\n",
    "second = set()\n",
    "\n",
    "for f in (['test','dev','train']):\n",
    "\n",
    "    tsv_file = open(f\"../../../MatchingText/STS-B/original/sts-{f}.tsv\")\n",
    "    read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "    for row in read_tsv:\n",
    "        if len(row) != 7: continue\n",
    "        if float(row[4])>= 2:\n",
    "            first.add(normalize_text(row[5]))\n",
    "            second.add(normalize_text(row[6]))\n",
    "            if row[5] not in ground_truth:\n",
    "                ground_truth[normalize_text(row[5])] = [normalize_text(row[6])]\n",
    "            else:\n",
    "                ground_truth[normalize_text(row[5])].append(normalize_text(row[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878fc290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:12:22.107642Z",
     "start_time": "2021-11-03T09:12:22.085267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86b3929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:12:22.361534Z",
     "start_time": "2021-11-03T09:12:22.355547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5004, 4987)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first), len(second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1fd7e3",
   "metadata": {},
   "source": [
    "# 1. TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005ec6cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:12:54.076552Z",
     "start_time": "2021-11-03T09:12:52.534944Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [00:01<00:00, 3279.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "G=nx.Graph()\n",
    "K = 2\n",
    "i = 0\n",
    "nodes_labels = {}\n",
    "claim_ids = {}\n",
    "id_claim = {}\n",
    "\n",
    "for claim in tqdm(first):\n",
    "    node = remove_stopwords(normalize_text(claim))\n",
    "    i+=1\n",
    "\n",
    "    node_name = str('CLM'+str(i))\n",
    "    G.add_node(node_name , label= node_name, type='Claim')\n",
    "    claim_ids[node_name] = claim\n",
    "    id_claim[claim] = node_name\n",
    "                \n",
    "        \n",
    "    n_grams = [gr.replace(' ','_') for gr in find_all_n_grams(node,K)]\n",
    "    n_grams = sorted(n_grams, key=lambda dist: len(dist),reverse = True)\n",
    "    \n",
    "    for tg in n_grams:\n",
    "        token = tg\n",
    "            \n",
    "        G.add_node(token,label=token, type='Token')\n",
    "            \n",
    "        if not G.has_edge(node_name,token): G.add_edge(node_name,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b1377a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:13:01.549631Z",
     "start_time": "2021-11-03T09:13:00.012776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4987/4987 [00:01<00:00, 3282.99it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "fact_ids = {}\n",
    "id_fact = {}\n",
    "node_maps = []\n",
    "\n",
    "for fact in tqdm(second):\n",
    "    node = remove_stopwords(normalize_text(fact))\n",
    "    i += 1\n",
    "    name = str('FCT'+ str(i))\n",
    "    \n",
    "    fact_ids[name] = fact\n",
    "    id_fact[fact] = name\n",
    "    \n",
    "    G.add_node(name,label = name, type='Fact')\n",
    "    \n",
    "    n_grams = [gr.replace(' ','_') for gr in find_all_n_grams(node,K)]\n",
    "    n_grams = sorted(n_grams, key=lambda dist: len(dist),reverse = True)\n",
    "    \n",
    "    for tg in n_grams:\n",
    "        token = tg\n",
    "        \n",
    "        if not G.has_node(token): continue\n",
    "\n",
    "        if not G.has_edge(name,token):            G.add_edge(name,token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c5a920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T09:13:02.553378Z",
     "start_time": "2021-11-03T09:13:02.530255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44176, 105647)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes()), len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57ab41",
   "metadata": {},
   "source": [
    "# Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d437d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T22:45:44.863499Z",
     "start_time": "2021-10-23T22:45:44.843528Z"
    }
   },
   "outputs": [],
   "source": [
    "import conceptnet_lite\n",
    "conceptnet_lite.connect(\"conceptnet.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621f439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T22:45:54.535612Z",
     "start_time": "2021-10-23T22:45:53.641527Z"
    }
   },
   "outputs": [],
   "source": [
    "from conceptnet_lite import Label, edges_for\n",
    "from tqdm import tqdm\n",
    "\n",
    "for node in tqdm(G.copy().nodes()):\n",
    "    if G.nodes()[node]['type'] != 'Token': continue\n",
    "    \n",
    "    try:\n",
    "        for e in edges_for(Label.get(text=G.nodes()[node]['label'].replace('_',' '), language='en').concepts, same_language=True):\n",
    "            if e.start.text == node:\n",
    "                new_node = e.end.text\n",
    "            else:\n",
    "                new_node = e.start.text\n",
    "            rel = e.relation.name\n",
    "            \n",
    "            for n in normalize_text(new_node).split():\n",
    "                if not G.has_node(n):\n",
    "                    G.add_node(n, label = n, type = 'Token')\n",
    "            G.add_edge(node,n,type= rel)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "for n in G.copy().nodes():\n",
    "    if G.degree()[n] < 2:\n",
    "        G.remove_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322a9cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T22:45:54.559799Z",
     "start_time": "2021-10-23T22:45:54.537221Z"
    }
   },
   "outputs": [],
   "source": [
    "len(G.nodes()),len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc90112",
   "metadata": {},
   "source": [
    "# Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d6957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T09:26:36.120165Z",
     "start_time": "2021-10-24T09:26:36.104079Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_walk(node,l):\n",
    "    res = ''\n",
    "    \n",
    "    p = 0\n",
    "    chosen = node\n",
    "    \n",
    "    res += chosen\n",
    "\n",
    "    while (p<l):\n",
    "        chosen = random.sample([n for n in nx.neighbors(G,chosen)],1)[0]\n",
    "        #if G.nodes[chosen]['type'] in ['Claim','Fact','Token','node']:\n",
    "        res += ' ' + chosen\n",
    "        p+=1\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "def generate_random_walks(k,l):\n",
    "    rws = []\n",
    "    \n",
    "    for i in tqdm(range(0,k),position=0):\n",
    "        for node in G.nodes():\n",
    "            if len([n for n in nx.neighbors(G,node)]) == 0:\n",
    "                continue\n",
    "            #if G.nodes[node]['type'] in ['Claim','Fact','node']:\n",
    "            rws.append(random_walk(node,l))\n",
    "    return rws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c306ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T09:27:49.464330Z",
     "start_time": "2021-10-24T09:26:36.303286Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "random_paths = generate_random_walks(100,l=25)\n",
    "for p in random_paths:\n",
    "    docs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f885b6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T09:27:49.468777Z",
     "start_time": "2021-10-24T09:27:49.465809Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03654d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T09:29:16.395837Z",
     "start_time": "2021-10-24T09:27:49.471393Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from tqdm import tqdm \n",
    "tagged_data = []\n",
    "for d in tqdm(docs,position=0):\n",
    "    tagged_data.append(word_tokenize(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009859d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-23T14:45:11.398Z"
    }
   },
   "outputs": [],
   "source": [
    "%env PYTHONHASHSEED=0\n",
    "max_epochs = 10\n",
    "vec_size = 100\n",
    "\n",
    "model = Word2Vec(size=vec_size, min_count=0, window=20, sg=1, seed=0, workers = 4)\n",
    "\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "print(\"Model is Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdbb68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T08:10:02.230837Z",
     "start_time": "2021-10-22T08:09:21.102185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claim_facts = {}\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "    if claim not in id_claim: continue\n",
    "    cl_id = id_claim[claim]\n",
    "    filtered_facts = {}\n",
    "    \n",
    "    if cl_id not in model.wv: continue\n",
    "    claim_facts[cl_id] = distance_w2v (model,cl_id,fact_ids,50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1afdeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T19:04:03.339931Z",
     "start_time": "2021-10-21T19:03:58.991985Z"
    }
   },
   "outputs": [],
   "source": [
    "for KK in [1,5,20,30000]: \n",
    "    i = 0\n",
    "    precision,recall,fs = 0,0,0\n",
    "    MAP, MR, hasP = 0,0,0\n",
    "\n",
    "    for claim in claim_facts:\n",
    "        \n",
    "        i+=1\n",
    "        preds = [fact_ids[f] for (f,j) in claim_facts[claim]][0:KK]\n",
    "        golds = ground_truth[claim_ids[claim]]\n",
    "\n",
    "        MAP += MAP_K(golds,preds)\n",
    "        MR += MRR(golds,preds)\n",
    "        hasP += HAS_POSITIVE(golds,preds)\n",
    "\n",
    "\n",
    "    print('\\n#################### ' + str(KK) + ' ###########################\\n')\n",
    "    print('MRR:',MR/i,'MAP:',MAP/i, 'HAS POSITIVE:', hasP/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923db97e",
   "metadata": {},
   "source": [
    "# 2. SenteneBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a4160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T07:49:49.607864Z",
     "start_time": "2021-10-20T07:46:17.181844Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "SBmodel = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b06bad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T12:47:52.964746Z",
     "start_time": "2021-11-02T12:46:29.379058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cf471b4eae496f98a38a359a41bf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=117.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sentences_embs_f = SBmodel.encode([s for s in fact_ids.values()],show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2183dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:15:05.607921Z",
     "start_time": "2021-11-02T12:47:52.967659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3753/3753 [1:27:12<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "st = time.time()\n",
    "pred_sentences = {}\n",
    "\n",
    "\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "    m_emb = SBmodel.encode(claim)\n",
    "  \n",
    "    temp = []\n",
    "    for s in range(0,len(fact_ids)):\n",
    "        temp.append(([r for r in fact_ids.keys()][s],cosine_similarity(m_emb.reshape(1, -1),sentences_embs_f[rv].reshape(1, -1))[0][0]))\n",
    "    pred_sentences[claim] = sorted(temp,key=lambda dist:dist[1],reverse=True)\n",
    "  \n",
    "#print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5025610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:15:16.053431Z",
     "start_time": "2021-11-02T14:15:05.609875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################### 1 ###########################\n",
      "\n",
      "MRR: 0.8206767918998135 MAP: 0.8205435651478817 HAS POSITIVE: 0.8206767918998135\n",
      "\n",
      "#################### 5 ###########################\n",
      "\n",
      "MRR: 0.8814681588062885 MAP: 0.8813349320543566 HAS POSITIVE: 0.9656274980015987\n",
      "\n",
      "#################### 20 ###########################\n",
      "\n",
      "MRR: 0.8849612105883561 MAP: 0.8848723927537349 HAS POSITIVE: 0.9944044764188649\n",
      "\n",
      "#################### 500 ###########################\n",
      "\n",
      "MRR: 0.8850912109314689 MAP: 0.8850023930968477 HAS POSITIVE: 0.9994670929922729\n"
     ]
    }
   ],
   "source": [
    "for KK in [1,5,20,500]: \n",
    "    i = 0\n",
    "    precision,recall,fs = 0,0,0\n",
    "    MAP, MR, hasP = 0,0,0\n",
    "\n",
    "    for sent in pred_sentences:\n",
    "        if sent not in ground_truth: continue\n",
    "        i+=1\n",
    "        preds = [fact_ids[f] for (f,j) in pred_sentences[sent]][0:KK]\n",
    "        golds = [f for f in ground_truth[sent]]\n",
    "\n",
    "        MAP += MAP_K(golds,preds)\n",
    "        MR += MRR(golds,preds)\n",
    "        hasP += HAS_POSITIVE(golds,preds)\n",
    "        \n",
    "    print('\\n#################### ' + str(KK) + ' ###########################\\n')\n",
    "    print('MRR:',MR/i,'MAP:',MAP/i, 'HAS POSITIVE:', hasP/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42cad2",
   "metadata": {},
   "source": [
    "# 3. ReRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "227b9a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:18:00.650847Z",
     "start_time": "2021-11-02T14:18:00.643252Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from gensim.summarization.bm25 import BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4eebcbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:18:00.949450Z",
     "start_time": "2021-11-02T14:18:00.887057Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in id_fact]\n",
    "results = BM25(corpus)\n",
    "sentences_full = {}\n",
    "for r in id_fact:    sentences_full[r] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7dd2324d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:19:03.561674Z",
     "start_time": "2021-11-02T14:18:01.599204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [01:01<00:00, 81.33it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sentences_BM25 = {}\n",
    "for sent in tqdm(ground_truth):\n",
    "    m_id = id_claim[sent]\n",
    "    text = sent\n",
    "    scores = results.get_scores((text).split())\n",
    "    arr = np.array(scores)\n",
    "    topK = arr.argsort()[::-1]\n",
    "    sentences_BM25[m_id] = [(id_fact[' '.join(corpus[idx])],scores[idx]) for idx in topK]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9fd4800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:19:19.081098Z",
     "start_time": "2021-11-02T14:19:17.288967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/pignal/.cache/torch/sentence_transformers/sbert.net_models_bert-base-nli-stsb-mean-tokens/0_BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "SBmodel = SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97366ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:19:19.092513Z",
     "start_time": "2021-11-02T14:19:19.086892Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "44d71858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:19:19.104249Z",
     "start_time": "2021-11-02T14:19:19.095463Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d348365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T14:28:55.788202Z",
     "start_time": "2021-11-02T14:19:19.106480Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4987/4987 [09:36<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeds_sent = {}\n",
    "embeds = {}\n",
    "for sent in tqdm(id_fact,position=0):\n",
    "    embeds [sent] = SBmodel.encode(rv)\n",
    "    \n",
    "    embeds_sent [sent] = []\n",
    "    \n",
    "    sents = nltk.tokenize.sent_tokenize(sent)\n",
    "    for s in sents:\n",
    "        embeds_sent[sent].append(SBmodel.encode(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0bd2afd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T17:33:44.427590Z",
     "start_time": "2021-11-02T14:28:55.790317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [3:04:48<00:00,  2.22s/it]  \n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "score = []\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "  m_emb = SBmodel.encode(claim)\n",
    "    \n",
    "  for s in id_fact:\n",
    "    temp = []\n",
    "    for sent in embeds_sent[s]:\n",
    "        temp.append(cosine_similarity(m_emb.reshape(1, -1),sent.reshape(1, -1))[0][0])\n",
    "    temp = sorted(temp,reverse=True)[0:3]\n",
    "    \n",
    "    temp.append(cosine_similarity(m_emb.reshape(1, -1),embeds[review].reshape(1, -1))[0][0])\n",
    "    \n",
    "    while len(temp) < K:        temp.append(0)\n",
    "        \n",
    "\n",
    "    \n",
    "    if id_fact[sent] in ground_truth[claim]: temp.append(1)\n",
    "    else: temp.append(0)\n",
    "        \n",
    "    score.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b69c1017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T17:34:25.829531Z",
     "start_time": "2021-11-02T17:33:44.429971Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.array(score)\n",
    "X = dataset[:,0:4]\n",
    "y = dataset[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "14728310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T17:34:25.890212Z",
     "start_time": "2021-11-02T17:34:25.832211Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import losses,optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=4, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bae7845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T17:57:07.970348Z",
     "start_time": "2021-11-02T17:34:25.891618Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24954948/24954948 [==============================] - 32s 1us/step - loss: 0.0065 - accuracy: 0.9999\n",
      "Epoch 2/50\n",
      "24954948/24954948 [==============================] - 32s 1us/step - loss: 1.4042e-08 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "24954948/24954948 [==============================] - 32s 1us/step - loss: 8.4218e-11 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.8796e-11 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 1.0557e-11 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 7.3484e-12 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 5.6309e-12 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 4.5719e-12 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 3.8490e-12 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 3.3106e-12 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 2.9333e-12 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 2.6129e-12 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 2.3570e-12 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 2.1508e-12 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.9713e-12 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.8273e-12 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.6964e-12 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.5773e-12 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.4724e-12 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.3881e-12 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.3147e-12 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.2460e-12 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 1.1808e-12 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 1.1190e-12 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 1.0650e-12 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 1.0178e-12 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 9.7405e-13 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 9.3225e-13 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 8.9221e-13 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 8.5421e-13 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 8.1988e-13 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 7.8914e-13 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 7.6078e-13 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 7.3356e-13 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 7.0736e-13 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 6.8210e-13 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 6.5792e-13 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 6.3961e-13 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 6.2612e-13 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 6.1302e-13 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "24954948/24954948 [==============================] - 26s 1us/step - loss: 6.0019e-13 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "24954948/24954948 [==============================] - 26s 1us/step - loss: 5.8764e-13 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "24954948/24954948 [==============================] - 26s 1us/step - loss: 5.7535e-13 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 5.6331e-13 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "24954948/24954948 [==============================] - 28s 1us/step - loss: 5.5176e-13 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "24954948/24954948 [==============================] - 23s 1us/step - loss: 5.4100e-13 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "24954948/24954948 [==============================] - 24s 1us/step - loss: 5.3072e-13 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "24954948/24954948 [==============================] - 27s 1us/step - loss: 5.2064e-13 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "24954948/24954948 [==============================] - 24s 1us/step - loss: 5.1089e-13 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "24954948/24954948 [==============================] - 25s 1us/step - loss: 5.0169e-13 - accuracy: 1.0000\n",
      "1362.0752198696136\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "class_weight = {0: 1.,1: 50.}\n",
    "\n",
    "model.fit(X, y, epochs=50, batch_size=2048)\n",
    "print(time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2c95654b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:16:53.684848Z",
     "start_time": "2021-11-02T17:57:07.972016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [3:19:42<00:00,  2.39s/it]  \n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "  m_emb = SBmodel.encode(claim)\n",
    "\n",
    "  seen = []\n",
    "  data,scores = [],[]\n",
    "\n",
    "  for sent in id_fact:\n",
    "    seen.append(id_fact[sent])\n",
    "\n",
    "    temp = []\n",
    "    for sent in embeds_sent[sent]:\n",
    "        temp.append(cosine_similarity(m_emb.reshape(1, -1),sent.reshape(1, -1))[0][0])\n",
    "    temp = sorted(temp,reverse=True)[0:3]\n",
    "    \n",
    "    temp.append(cosine_similarity(m_emb.reshape(1, -1),review_embeds[review].reshape(1, -1))[0][0])\n",
    "    \n",
    "    while len(temp) < K-1:        temp.append(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data.append(temp)\n",
    "\n",
    "  res = model.predict(np.array(data))\n",
    "        \n",
    "  for i in range(0,len(res)):\n",
    "      scores.append((seen[i],res[i][0]))\n",
    "        \n",
    "  predictions[claim] = sorted(scores, key=lambda dist: dist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25055cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:17:10.709015Z",
     "start_time": "2021-11-02T21:17:10.706431Z"
    }
   },
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca02359b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:17:12.315140Z",
     "start_time": "2021-11-02T21:17:10.711070Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_SB = predictions\n",
    "predictions_BM25 = sentences_BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "976f9ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:17:12.328166Z",
     "start_time": "2021-11-02T21:17:12.316347Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dlib.ranking_pair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0aa6ee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T22:00:23.651385Z",
     "start_time": "2021-11-02T21:17:12.329655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [42:17<00:00,  1.97it/s] \n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "    if claim not in predictions_SB or id_claim[claim] not in predictions_BM25: continue\n",
    "\n",
    "    m_BM = [i for (i,j) in predictions_BM25[ id_claim[claim]]]\n",
    "    m_SB = [i for (i,j) in predictions_SB[claim]]\n",
    "    \n",
    "    \n",
    "    for r in fact_ids:\n",
    "        if fact_ids[r] in ground_truth[claim]: \n",
    "            data.relevant.append(dlib.vector([m_BM.index(r)+1, m_SB.index(r)+1]))\n",
    "        else:  \n",
    "            data.nonrelevant.append(dlib.vector([m_BM.index(r)+1, m_SB.index(r)+1]))\n",
    "\n",
    "trainer = dlib.svm_rank_trainer()\n",
    "trainer.c = 1000\n",
    "\n",
    "rank = trainer.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d91e428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T22:41:06.995247Z",
     "start_time": "2021-11-02T22:00:23.652992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5004/5004 [40:42<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "rerank = {}\n",
    "\n",
    "for claim in tqdm(ground_truth,position=0):\n",
    "    if claim not in predictions_SB or id_claim[claim] not in predictions_BM25: continue\n",
    "    m_BM = [i for (i,j) in predictions_BM25[ id_claim[claim]]]\n",
    "    m_SB = [i for (i,j) in predictions_SB[claim]]\n",
    "    \n",
    "    temp = []\n",
    "    for r in fact_ids:\n",
    "        temp.append((r,rank(dlib.vector([m_BM.index(r)+1, m_SB.index(r)+1]))))\n",
    "    temp = sorted(temp, key=lambda dist: dist[1],reverse = True)\n",
    "    rerank[claim] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34d72db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T22:41:21.745191Z",
     "start_time": "2021-11-02T22:41:06.996808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################### 1 ###########################\n",
      "\n",
      "MRR: 0.7144284572342127 MAP: 0.7143285371702638 HAS POSITIVE: 0.7144284572342127\n",
      "\n",
      "#################### 5 ###########################\n",
      "\n",
      "MRR: 0.7887023714361845 MAP: 0.7886024513722356 HAS POSITIVE: 0.8990807354116707\n",
      "\n",
      "#################### 20 ###########################\n",
      "\n",
      "MRR: 0.7962447867284447 MAP: 0.7961698466804831 HAS POSITIVE: 0.9670263788968825\n",
      "\n",
      "#################### 200 ###########################\n",
      "\n",
      "MRR: 0.7970618005843749 MAP: 0.7969868605364132 HAS POSITIVE: 0.9950039968025579\n"
     ]
    }
   ],
   "source": [
    "for KK in [1,5,20,200]: \n",
    "    i = 0\n",
    "    precision,recall,fs = 0,0,0\n",
    "    MAP, MR, hasP = 0,0,0\n",
    "\n",
    "    for sent in rerank:\n",
    "        if sent not in ground_truth: continue\n",
    "        i+=1\n",
    "        preds = [fact_ids[f] for (f,j) in rerank[sent]][0:KK]\n",
    "        golds = [f for f in ground_truth[sent]]\n",
    "\n",
    "        MAP += MAP_K(golds,preds)\n",
    "        MR += MRR(golds,preds)\n",
    "        hasP += HAS_POSITIVE(golds,preds)\n",
    "        \n",
    "    print('\\n#################### ' + str(KK) + ' ###########################\\n')\n",
    "    print('MRR:',MR/i,'MAP:',MAP/i, 'HAS POSITIVE:', hasP/i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
