{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:54:18.602618Z",
     "start_time": "2021-07-23T10:54:15.442394Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from graphUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJbOTHQ7L70W"
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:54:30.236147Z",
     "start_time": "2021-07-23T10:54:30.184927Z"
    },
    "id": "SODgrj6JMAdY"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df = pickle.load(open('../../data/imdb/imdb_reviews_1000film.df','rb'))\n",
    "ground_truth = pickle.load(open('../../data/imdb/imdb_GT.pkl','rb'))\n",
    "review_ids = pickle.load(open('../../data/imdb/imdb_reviewIDs.pkl','rb'))\n",
    "row_ids = pickle.load(open('../../data/imdb/imdb_movieIDs.pkl','rb'))\n",
    "id_revs = inv_map = {v: k for k, v in review_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXWmQEbYMCWT"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "movies_dic = {}\n",
    "with open('../../data/imdb/imdb_movielens.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        if row[12].replace('_',' ') not in movies_dic: \n",
    "            movies_dic[row[12].replace('_',' ')] = []\n",
    "            \n",
    "        temp = [r.replace('_',' ') for r in row[0:10]]\n",
    "        \n",
    "        month,year = '',''\n",
    "        if len(row[10]) > 0:        \n",
    "            month = datetime.date(1900, int(row[10][4::]), 1).strftime('%B')\n",
    "            year = row[10][0:4]\n",
    "        \n",
    "        temp.append(month.lower() + ' ' + year)\n",
    "        temp.append(int(float(row[14])))\n",
    "        \n",
    "        movies_dic[row[12].replace('_',' ')].append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWVbNe4KL4Cm"
   },
   "source": [
    "# Ditto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fs2R_Ro45H-L",
    "outputId": "19593adb-79d5-48b7-8af6-e7c98cf71bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
      "\u001b[K     |████████████████████████████████| 827.9MB 47.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.2.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
      "Building wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180945 sha256=a89ca618725130a6e737151949c42b62e73a218d360aaeb848de4edb842e7299\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-81d49x0x/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "beYF8bCT24zc",
    "outputId": "b3e365da-12e6-4243-801a-b9e98bf68e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ditto'...\n",
      "remote: Enumerating objects: 234, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 234 (delta 5), reused 9 (delta 3), pack-reused 220\u001b[K\n",
      "Receiving objects: 100% (234/234), 26.78 MiB | 22.82 MiB/s, done.\n",
      "Resolving deltas: 100% (107/107), done.\n",
      "/content/ditto\n",
      "Collecting gensim==3.8.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2MB 1.4MB/s \n",
      "\u001b[?25hCollecting numpy==1.17.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/af/4fc72f9d38e43b092e91e5b8cb9956d25b2e3ff8c75aed95df5569e4734e/numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K     |████████████████████████████████| 20.0MB 289kB/s \n",
      "\u001b[?25hRequirement already satisfied: regex==2019.12.20 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2019.12.20)\n",
      "Collecting scipy==1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/69/d3819eae2af1811895e64b6277669906e861053b93000534a5809940f321/scipy-1.3.2-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 1.5MB/s \n",
      "\u001b[?25hCollecting sentencepiece==0.1.85\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/e0/1264990c559fb945cfb6664742001608e1ed8359eeec6722830ae085062b/sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 36.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Collecting spacy==2.2.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/76/1f30264c433f9c3c84171fa03f4b6bb5f3303df7781d21554d25045873f4/spacy-2.2.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 15.8MB/s \n",
      "\u001b[?25hCollecting tensorboardX==2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 44.7MB/s \n",
      "\u001b[?25hCollecting torch==1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 22kB/s \n",
      "\u001b[?25hCollecting tqdm==4.41.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/c3/d049cf3fb31094ee045ec1ee29fffac218c91e82c8838c49ab4c3e52627b/tqdm-4.41.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
      "\u001b[?25hCollecting transformers==2.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\u001b[K     |████████████████████████████████| 573kB 39.7MB/s \n",
      "\u001b[?25hCollecting jsonlines==1.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
      "Collecting nltk==3.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 41.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->-r requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (57.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (1.1.3)\n",
      "Collecting thinc<7.4.0,>=7.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/53/d11d2faa6921e55c37ad2cd56b0866a9e6df647fb547cfb69a50059d759c/thinc-7.3.1-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 40.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (2.23.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r requirements.txt (line 8)) (3.17.3)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 40.3MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 22.5MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/96/c5b23f4d9dfcaa63764b8debd294a30f8c0fe0ea425a68231e4559dcacf4/boto3-1.18.1-py3-none-any.whl (131kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 41.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->-r requirements.txt (line 11)) (3.0.12)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r requirements.txt (line 13)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 7)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 7)) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 7)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 7)) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 7)) (4.6.1)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting botocore<1.22.0,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/cf2cc2a9de0feb0b0a071dcdecab16df5153a29e795965e4c4b0c28708f8/botocore-1.21.1-py3-none-any.whl (7.7MB)\n",
      "\u001b[K     |████████████████████████████████| 7.7MB 38.2MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/84/fc3717a7b7f0f6bb08af593127171f08e3e0087c197922da09c01bfe7c3a/s3transfer-0.5.0-py3-none-any.whl (79kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 9.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 7)) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.1->boto3->transformers==2.8.0->-r requirements.txt (line 11)) (2.8.1)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434693 sha256=435e898ffd314afb6d64703ea7277f7277f482c2099598b0635d1d29063b4ffb\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.17.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.17.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.21.1 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, gensim, sentencepiece, tqdm, thinc, spacy, tensorboardX, torch, sacremoses, tokenizers, jmespath, botocore, s3transfer, boto3, transformers, jsonlines, nltk\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "  Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "  Found existing installation: thinc 7.4.0\n",
      "    Uninstalling thinc-7.4.0:\n",
      "      Successfully uninstalled thinc-7.4.0\n",
      "  Found existing installation: spacy 2.2.4\n",
      "    Uninstalling spacy-2.2.4:\n",
      "      Successfully uninstalled spacy-2.2.4\n",
      "  Found existing installation: torch 1.9.0+cu102\n",
      "    Uninstalling torch-1.9.0+cu102:\n",
      "      Successfully uninstalled torch-1.9.0+cu102\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed boto3-1.18.1 botocore-1.21.1 gensim-3.8.1 jmespath-0.10.0 jsonlines-1.2.0 nltk-3.5 numpy-1.17.4 s3transfer-0.5.0 sacremoses-0.0.45 scipy-1.3.2 sentencepiece-0.1.85 spacy-2.2.3 tensorboardX-2.0 thinc-7.3.1 tokenizers-0.5.2 torch-1.4.0 tqdm-4.41.0 transformers-2.8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Snippext_public'...\n",
      "remote: Enumerating objects: 402, done.\u001b[K\n",
      "remote: Counting objects: 100% (402/402), done.\u001b[K\n",
      "remote: Compressing objects: 100% (257/257), done.\u001b[K\n",
      "remote: Total 402 (delta 191), reused 289 (delta 94), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (402/402), 12.67 MiB | 17.07 MiB/s, done.\n",
      "Resolving deltas: 100% (191/191), done.\n",
      "/content/ditto/Snippext_public\n",
      "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
      "Collecting numpy==1.19.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/04/c3846024ddc7514cde17087f62f0502abf85c53e8f69f6312c70db6d144e/numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5MB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex==2019.12.20 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2019.12.20)\n",
      "Requirement already satisfied: spacy==2.2.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.85 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.1.85)\n",
      "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: tensorboardX==2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.0)\n",
      "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: tqdm==4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.41.0)\n",
      "Collecting transformers==3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 47.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: jsonlines==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.2.0)\n",
      "Collecting nltk==3.4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 41.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (57.2.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (0.4.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (3.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.3->-r requirements.txt (line 4)) (2.0.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->-r requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r requirements.txt (line 8)) (3.17.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 11)) (21.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 11)) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 11)) (0.0.45)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 44.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 4)) (4.6.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 4)) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0->-r requirements.txt (line 11)) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0->-r requirements.txt (line 11)) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 4)) (3.7.4.3)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449921 sha256=3e1d6e9907fb53c182f1daf654e9a7582b51fc601d288c86d3c6e8e5747cff10\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, tokenizers, transformers, nltk\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "  Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "  Found existing installation: transformers 2.8.0\n",
      "    Uninstalling transformers-2.8.0:\n",
      "      Successfully uninstalled transformers-2.8.0\n",
      "  Found existing installation: nltk 3.5\n",
      "    Uninstalling nltk-3.5:\n",
      "      Successfully uninstalled nltk-3.5\n",
      "Successfully installed nltk-3.4.5 numpy-1.19.2 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ditto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/megagonlabs/ditto\n",
    "%cd ditto\n",
    "!pip install -r requirements.txt\n",
    "!git clone https://github.com/rit-git/Snippext_public\n",
    "%cd Snippext_public\n",
    "!pip install -r requirements.txt\n",
    "%cd ..\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONzTUwyC281Z",
    "outputId": "3bbba4b0-92b9-4579-adcc-60427e81551e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 8102, done.\u001b[K\n",
      "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
      "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
      "remote: Total 8102 (delta 92), reused 123 (delta 63), pack-reused 7913\u001b[K\n",
      "Receiving objects: 100% (8102/8102), 14.15 MiB | 19.91 MiB/s, done.\n",
      "Resolving deltas: 100% (5493/5493), done.\n",
      "/content/ditto/apex\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-35vlpq0d\n",
      "Created temporary directory: /tmp/pip-req-tracker-tn6tevi9\n",
      "Created requirements tracker '/tmp/pip-req-tracker-tn6tevi9'\n",
      "Created temporary directory: /tmp/pip-install-6m4jwsxf\n",
      "Processing /content/ditto/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-1gmnhqei\n",
      "  Added file:///content/ditto/apex to build tracker '/tmp/pip-req-tracker-tn6tevi9'\n",
      "    Running setup.py (path:/tmp/pip-req-build-1gmnhqei/setup.py) egg_info for package from file:///content/ditto/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.4.0\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file '/tmp/pip-req-build-1gmnhqei/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-1gmnhqei/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-1gmnhqei has version 0.1, which satisfies requirement apex==0.1 from file:///content/ditto/apex\n",
      "  Removed apex==0.1 from file:///content/ditto/apex from build tracker '/tmp/pip-req-tracker-tn6tevi9'\n",
      "Building wheels for collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-wheel-dloswzip\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-dloswzip\n",
      "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-1gmnhqei/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-1gmnhqei/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-dloswzip --python-tag cp37\n",
      "\n",
      "\n",
      "  torch.__version__  = 1.4.0\n",
      "\n",
      "\n",
      "  /tmp/pip-req-build-1gmnhqei/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/apex\n",
      "  copying apex/__init__.py -> build/lib/apex\n",
      "  creating build/lib/apex/RNN\n",
      "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
      "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
      "  creating build/lib/apex/mlp\n",
      "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
      "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
      "  creating build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
      "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
      "  creating build/lib/apex/amp\n",
      "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
      "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
      "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
      "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
      "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
      "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
      "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
      "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
      "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
      "  creating build/lib/apex/contrib\n",
      "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
      "  creating build/lib/apex/parallel\n",
      "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
      "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "  creating build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
      "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
      "  creating build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
      "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
      "  creating build/lib/apex/normalization\n",
      "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
      "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
      "  creating build/lib/apex/pyprof\n",
      "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
      "  creating build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
      "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
      "  creating build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
      "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
      "  creating build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "  creating build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
      "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
      "  creating build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
      "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
      "  creating build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
      "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
      "  creating build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
      "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
      "  creating build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
      "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
      "  creating build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
      "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
      "  creating build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
      "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
      "  creating build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "  creating build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
      "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
      "  creating build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
      "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
      "  creating build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
      "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
      "  installing to build/bdist.linux-x86_64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating build/bdist.linux-x86_64\n",
      "  creating build/bdist.linux-x86_64/wheel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
      "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
      "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  creating apex.egg-info\n",
      "  writing apex.egg-info/PKG-INFO\n",
      "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "  writing top-level names to apex.egg-info/top_level.txt\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
      "  running install_scripts\n",
      "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
      "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
      "  creating '/tmp/pip-wheel-dloswzip/apex-0.1-cp37-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "  adding 'apex/__init__.py'\n",
      "  adding 'apex/RNN/RNNBackend.py'\n",
      "  adding 'apex/RNN/__init__.py'\n",
      "  adding 'apex/RNN/cells.py'\n",
      "  adding 'apex/RNN/models.py'\n",
      "  adding 'apex/amp/__init__.py'\n",
      "  adding 'apex/amp/__version__.py'\n",
      "  adding 'apex/amp/_amp_state.py'\n",
      "  adding 'apex/amp/_initialize.py'\n",
      "  adding 'apex/amp/_process_optimizer.py'\n",
      "  adding 'apex/amp/amp.py'\n",
      "  adding 'apex/amp/compat.py'\n",
      "  adding 'apex/amp/frontend.py'\n",
      "  adding 'apex/amp/handle.py'\n",
      "  adding 'apex/amp/opt.py'\n",
      "  adding 'apex/amp/rnn_compat.py'\n",
      "  adding 'apex/amp/scaler.py'\n",
      "  adding 'apex/amp/utils.py'\n",
      "  adding 'apex/amp/wrap.py'\n",
      "  adding 'apex/amp/lists/__init__.py'\n",
      "  adding 'apex/amp/lists/functional_overrides.py'\n",
      "  adding 'apex/amp/lists/tensor_overrides.py'\n",
      "  adding 'apex/amp/lists/torch_overrides.py'\n",
      "  adding 'apex/contrib/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/__init__.py'\n",
      "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
      "  adding 'apex/contrib/bottleneck/test.py'\n",
      "  adding 'apex/contrib/fmha/__init__.py'\n",
      "  adding 'apex/contrib/fmha/fmha.py'\n",
      "  adding 'apex/contrib/groupbn/__init__.py'\n",
      "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "  adding 'apex/contrib/layer_norm/__init__.py'\n",
      "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
      "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "  adding 'apex/contrib/optimizers/__init__.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
      "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "  adding 'apex/contrib/sparsity/__init__.py'\n",
      "  adding 'apex/contrib/sparsity/asp.py'\n",
      "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
      "  adding 'apex/contrib/transducer/__init__.py'\n",
      "  adding 'apex/contrib/transducer/transducer.py'\n",
      "  adding 'apex/contrib/xentropy/__init__.py'\n",
      "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "  adding 'apex/fp16_utils/__init__.py'\n",
      "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "  adding 'apex/fp16_utils/fp16util.py'\n",
      "  adding 'apex/fp16_utils/loss_scaler.py'\n",
      "  adding 'apex/mlp/__init__.py'\n",
      "  adding 'apex/mlp/mlp.py'\n",
      "  adding 'apex/multi_tensor_apply/__init__.py'\n",
      "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "  adding 'apex/normalization/__init__.py'\n",
      "  adding 'apex/normalization/fused_layer_norm.py'\n",
      "  adding 'apex/optimizers/__init__.py'\n",
      "  adding 'apex/optimizers/fused_adagrad.py'\n",
      "  adding 'apex/optimizers/fused_adam.py'\n",
      "  adding 'apex/optimizers/fused_lamb.py'\n",
      "  adding 'apex/optimizers/fused_novograd.py'\n",
      "  adding 'apex/optimizers/fused_sgd.py'\n",
      "  adding 'apex/parallel/LARC.py'\n",
      "  adding 'apex/parallel/__init__.py'\n",
      "  adding 'apex/parallel/distributed.py'\n",
      "  adding 'apex/parallel/multiproc.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "  adding 'apex/parallel/sync_batchnorm.py'\n",
      "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "  adding 'apex/pyprof/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/__init__.py'\n",
      "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
      "  adding 'apex/pyprof/parse/__init__.py'\n",
      "  adding 'apex/pyprof/parse/__main__.py'\n",
      "  adding 'apex/pyprof/parse/db.py'\n",
      "  adding 'apex/pyprof/parse/kernel.py'\n",
      "  adding 'apex/pyprof/parse/nvvp.py'\n",
      "  adding 'apex/pyprof/parse/parse.py'\n",
      "  adding 'apex/pyprof/prof/__init__.py'\n",
      "  adding 'apex/pyprof/prof/__main__.py'\n",
      "  adding 'apex/pyprof/prof/activation.py'\n",
      "  adding 'apex/pyprof/prof/base.py'\n",
      "  adding 'apex/pyprof/prof/blas.py'\n",
      "  adding 'apex/pyprof/prof/conv.py'\n",
      "  adding 'apex/pyprof/prof/convert.py'\n",
      "  adding 'apex/pyprof/prof/data.py'\n",
      "  adding 'apex/pyprof/prof/dropout.py'\n",
      "  adding 'apex/pyprof/prof/embedding.py'\n",
      "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
      "  adding 'apex/pyprof/prof/linear.py'\n",
      "  adding 'apex/pyprof/prof/loss.py'\n",
      "  adding 'apex/pyprof/prof/misc.py'\n",
      "  adding 'apex/pyprof/prof/normalization.py'\n",
      "  adding 'apex/pyprof/prof/optim.py'\n",
      "  adding 'apex/pyprof/prof/output.py'\n",
      "  adding 'apex/pyprof/prof/pointwise.py'\n",
      "  adding 'apex/pyprof/prof/pooling.py'\n",
      "  adding 'apex/pyprof/prof/prof.py'\n",
      "  adding 'apex/pyprof/prof/randomSample.py'\n",
      "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
      "  adding 'apex/pyprof/prof/reduction.py'\n",
      "  adding 'apex/pyprof/prof/softmax.py'\n",
      "  adding 'apex/pyprof/prof/usage.py'\n",
      "  adding 'apex/pyprof/prof/utility.py'\n",
      "  adding 'apex/reparameterization/__init__.py'\n",
      "  adding 'apex/reparameterization/reparameterization.py'\n",
      "  adding 'apex/reparameterization/weight_norm.py'\n",
      "  adding 'apex-0.1.dist-info/LICENSE'\n",
      "  adding 'apex-0.1.dist-info/METADATA'\n",
      "  adding 'apex-0.1.dist-info/WHEEL'\n",
      "  adding 'apex-0.1.dist-info/top_level.txt'\n",
      "  adding 'apex-0.1.dist-info/RECORD'\n",
      "  removing build/bdist.linux-x86_64/wheel\n",
      "\u001b[?25hdone\n",
      "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=205208 sha256=a293745587cb93a13ee328b06cb7304ebd1d64f32f8b1ebf05f49b08b18800ca\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-35vlpq0d/wheels/c4/2f/08/44321bebb4e4928e530effdcf9415bfb8cffd3254b4b0d0d27\n",
      "  Removing source in /tmp/pip-req-build-1gmnhqei\n",
      "Successfully built apex\n",
      "Installing collected packages: apex\n",
      "\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-tn6tevi9'\n",
      "/content/ditto\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "%cd apex\n",
    "!pip install -v --no-cache-dir ./\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nj4WBBdh4JmW",
    "outputId": "c873daea-cfc5-4665-a040-8b71d43a5811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urllib3==1.25.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 7.4MB/s \n",
      "\u001b[?25hCollecting awscli\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/c3/740d73a0f9b7166ff62c6b31b627fd8bfa889da8dae65c0226beb4db6a41/awscli-1.20.1-py3-none-any.whl (3.6MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6MB 33.7MB/s \n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K     |████████████████████████████████| 552kB 36.1MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: botocore==1.21.1 in /usr/local/lib/python3.7/dist-packages (from awscli) (1.21.1)\n",
      "Collecting colorama<0.4.4,>=0.2.5\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from awscli) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.21.1->awscli) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.21.1->awscli) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.21.1->awscli) (1.15.0)\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, docutils, colorama, awscli\n",
      "  Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Found existing installation: docutils 0.17.1\n",
      "    Uninstalling docutils-0.17.1:\n",
      "      Successfully uninstalled docutils-0.17.1\n",
      "Successfully installed awscli-1.20.1 colorama-0.4.3 docutils-0.15.2 urllib3-1.25.4\n"
     ]
    }
   ],
   "source": [
    "# some issue with colab\n",
    "!pip install --upgrade \"urllib3==1.25.4\" awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHJvE3Dk2tCn"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNGtvB3lzpXn"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "file = open('data/er_magellan/Structured/Beer/train.txt','w')\n",
    "\n",
    "\n",
    "for movie in [m for m in ground_truth.keys()][0:int(0.6*len(ground_truth))]:\n",
    "    if movie not in movies_dic: continue\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    #text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    text = re.sub('\\t',' ',text)\n",
    "\n",
    "\n",
    "    row = []\n",
    "    for r in ground_truth[movie]:\n",
    "        rev = re.sub('\\t',' ',review_ids[r])    \n",
    "        rev = re.sub('\\n',' ',rev)\n",
    "        rev = re.sub(' +',' ',rev)\n",
    "\n",
    "\n",
    "        file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t1\\n' )\n",
    "\n",
    "        \n",
    "    for r in random.sample(review_ids.keys(),len(review_ids)):  \n",
    "        if r not in ground_truth[movie]:\n",
    "            rev = re.sub('\\t',' ',review_ids[r])  \n",
    "            rev = re.sub('\\n',' ',rev)\n",
    "            rev = re.sub(' +',' ',rev)\n",
    "\n",
    "\n",
    "            file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t0\\n' )\n",
    "\n",
    "\n",
    "file = open('data/er_magellan/Structured/Beer/valid.txt','w')\n",
    "\n",
    "\n",
    "for movie in [m for m in ground_truth.keys()][int(0.5*len(ground_truth)):int(0.53*len(ground_truth))]:\n",
    "    if movie not in movies_dic: continue\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    #text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    text = re.sub('\\t',' ',text)\n",
    "\n",
    "    row = []\n",
    "    for r in ground_truth[movie]:\n",
    "        rev = re.sub('\\t',' ',review_ids[r])    \n",
    "        rev = re.sub('\\n',' ',rev)\n",
    "        rev = re.sub(' +',' ',rev)\n",
    "\n",
    "        file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t1\\n' )\n",
    "\n",
    "        \n",
    "    for r in random.sample(review_ids.keys(),len(review_ids)):  \n",
    "        if r not in ground_truth[movie]:\n",
    "            rev = re.sub('\\t',' ',review_ids[r])    \n",
    "            rev = re.sub('\\n',' ',rev)\n",
    "            rev = re.sub(' +',' ',rev)\n",
    "\n",
    "            file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t0\\n' )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file = open('data/er_magellan/Structured/Beer/test.txt','w')\n",
    "\n",
    "\n",
    "for movie in [m for m in ground_truth.keys()][int(0.55*len(ground_truth)):int(0.6*len(ground_truth))]:\n",
    "    if movie not in movies_dic: continue\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    #text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    text = re.sub('\\t',' ',text)\n",
    "\n",
    "    row = []\n",
    "    for r in ground_truth[movie]:\n",
    "        rev = re.sub('\\t',' ',review_ids[r])    \n",
    "        rev = re.sub('\\n',' ',rev)\n",
    "        rev = re.sub(' +',' ',rev)\n",
    "      \n",
    "        file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t1\\n' )\n",
    "        \n",
    "    for r in random.sample(review_ids.keys(),len(review_ids)):  \n",
    "        if r not in ground_truth[movie]:\n",
    "            rev = re.sub('\\t',' ',review_ids[r])    \n",
    "            rev = re.sub('\\n',' ',rev)\n",
    "            rev = re.sub(' +',' ',rev)\n",
    "\n",
    "            file.write('COL movie VAL ' + text + '\\tCOL movie VAL ' + rev + '\\t0\\n' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDgr7Swc22K-",
    "outputId": "dccad8fe-8a28-481e-f9fa-209dab3a6103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-19 07:49:39.824984: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Downloading: 100% 232k/232k [00:00<00:00, 853kB/s]\n",
      "Downloading: 100% 442/442 [00:00<00:00, 387kB/s]\n",
      "Downloading: 100% 268M/268M [00:05<00:00, 47.5MB/s]\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "/usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py:25: UserWarning: An input tensor was not cuda.\n",
      "  warnings.warn(\"An input tensor was not cuda.\")\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "=====sanity check======\n",
      "words: COL movie VAL callum rennie thomas lennon jorja fox black and white r christopher nolan english usa  2000 [SEP] COL movie VAL I am so very tired of people reviewing movies, which are subjective by nature, as blanketly \"best ever\" this and \"best ever\" that. That's simply a case of small minds and big egos at work. There are so many great Holmes films and portrayals out there, that it's asinine to declare any one film or one actor as \"the best\". Most reviewers who rave about this film claim how it finally got \"it\" right. Got what right? Your personal interpretation of Sherlock Holmes in your mind? What about Jack's mind? What about Sally's? Some go so far as to claim this film merits something extra because it debunks the very debatable myth that Holmes never wore the famous deerstalker cap. For the record, Holmes was described as wearing a hat made of \"cloth\" that was an \"ear-flapped traveling cap\" in the story Silver Blaze. Original illustrator Sidney Paget saw that as meaning a deerstalker in his mind and an image even more famous than the writing on the page was born. Sounds like Paget made a pretty sound deduction too if you ask me. Regardless, if you personally don't think Holmes ever wore a deerstalker in the stories would facts like that alone or in combo boost a film so much as to make its interpretation \"the best\". Equally valid claims can be made that Basil Rathbone, Jeremy Brett, Arthur Wontner, Douglas Wilmer, Peter Cushing, Clive Merrison, and others depending on your taste are the best. The question is, was the movie any good on its own and were the performances fun. I don't give a hoot if it was exactly how you pictured Holmes in your mind or if you thought it was better/worse than other Holmes' films or that it somehow isn't as authentic because it wasn't a verbatim dramatization of a Conan Doyle tale, etc (Jeremy Brett fans, you know what I'm talking about). If you liked the movie, great. If you like other Holmes' a lot better, more power to you. I personally think the new Sherlock Holmes film took a lot of hinted at bits of Holmes' personality and skills from the canon and gave those characteristics the spotlight. That's fine. Those aren't the qualities that took reign when I read the stories, but who cares? Why would I want to see the exact same thing I saw when I read the books? That would make for a monotonous world. Hurray for everybody's various interpretations and subjective and wonderfully different tastes! There are no gospel truths about movies or books or art, so please just say you \"liked it a lot\" instead of it was \"the best\". That's so unhelpful. Just tell me what you liked about it as a film on its own without comparing it to any books, or other versions/interpretations. That's like saying one food item is \"the best\". It's ridiculous. On a final note, this new interpretation is a welcome addition to the world of Sherlock Holmes. It doesn't diminish any of the older films or television series. It stands on its own as another fun ride for fans of mystery, action, and those who love many things Sherlock.\n",
      "x: [  101  8902  3185 11748 15229 14916  8034  2726 14294  8183  2099  3900\n",
      "  4419  2304  1998  2317  1054  5696 13401  2394  3915  2456   102  8902\n",
      "  3185 11748  1045  2572  2061  2200  5458  1997  2111 15252  5691  1010\n",
      "  2029  2024 20714  2011  3267  1010  2004  8768  2135  1000  2190  2412\n",
      "  1000  2023  1998  1000  2190  2412  1000  2008  1012  2008  1005  1055\n",
      "  3432  1037  2553  1997  2235  9273  1998  2502 13059  2015  2012  2147\n",
      "  1012  2045  2024  2061  2116  2307  9106  3152  1998 13954  2015  2041\n",
      "  2045  1010  2008  2009  1005  1055  2004  5498  2638  2000 13520  2151\n",
      "  2028  2143  2030  2028  3364  2004  1000  1996  2190  1000  1012  2087\n",
      " 15814  2040 23289  2055  2023  2143  4366  2129  2009  2633  2288  1000\n",
      "  2009  1000  2157  1012  2288  2054  2157   102]\n",
      "tokens: ['[CLS]', 'col', 'movie', 'val', 'callum', 'ren', '##nie', 'thomas', 'lennon', 'jo', '##r', '##ja', 'fox', 'black', 'and', 'white', 'r', 'christopher', 'nolan', 'english', 'usa', '2000', '[SEP]', 'col', 'movie', 'val', 'i', 'am', 'so', 'very', 'tired', 'of', 'people', 'reviewing', 'movies', ',', 'which', 'are', 'subjective', 'by', 'nature', ',', 'as', 'blanket', '##ly', '\"', 'best', 'ever', '\"', 'this', 'and', '\"', 'best', 'ever', '\"', 'that', '.', 'that', \"'\", 's', 'simply', 'a', 'case', 'of', 'small', 'minds', 'and', 'big', 'ego', '##s', 'at', 'work', '.', 'there', 'are', 'so', 'many', 'great', 'holmes', 'films', 'and', 'portrayal', '##s', 'out', 'there', ',', 'that', 'it', \"'\", 's', 'as', '##ini', '##ne', 'to', 'declare', 'any', 'one', 'film', 'or', 'one', 'actor', 'as', '\"', 'the', 'best', '\"', '.', 'most', 'reviewers', 'who', 'rave', 'about', 'this', 'film', 'claim', 'how', 'it', 'finally', 'got', '\"', 'it', '\"', 'right', '.', 'got', 'what', 'right', '[SEP]']\n",
      "is_heads: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "y: 0\n",
      "tags: 0\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "seqlen: 128\n",
      "task_name: Structured/Beer\n",
      "=======================\n",
      "step: 0, task: Structured/Beer, loss: 0.5966986417770386\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "step: 10, task: Structured/Beer, loss: 0.5990505814552307\n",
      "step: 20, task: Structured/Beer, loss: 0.5554155111312866\n",
      "step: 30, task: Structured/Beer, loss: 0.47161489725112915\n",
      "step: 40, task: Structured/Beer, loss: 0.37403666973114014\n",
      "step: 50, task: Structured/Beer, loss: 0.24815289676189423\n",
      "step: 60, task: Structured/Beer, loss: 0.13891266286373138\n",
      "step: 70, task: Structured/Beer, loss: 0.06729941070079803\n",
      "step: 80, task: Structured/Beer, loss: 0.016772495582699776\n",
      "step: 90, task: Structured/Beer, loss: 0.010811012238264084\n",
      "step: 100, task: Structured/Beer, loss: 0.006525153294205666\n",
      "step: 110, task: Structured/Beer, loss: 0.04543253779411316\n",
      "step: 120, task: Structured/Beer, loss: 0.004087159410119057\n",
      "step: 130, task: Structured/Beer, loss: 0.0032801609486341476\n",
      "step: 140, task: Structured/Beer, loss: 0.0028313789516687393\n",
      "step: 150, task: Structured/Beer, loss: 0.0028374791145324707\n",
      "step: 160, task: Structured/Beer, loss: 0.003051627427339554\n",
      "step: 170, task: Structured/Beer, loss: 0.002866905415430665\n",
      "step: 180, task: Structured/Beer, loss: 0.0027026478201150894\n",
      "step: 190, task: Structured/Beer, loss: 0.04626081511378288\n",
      "step: 200, task: Structured/Beer, loss: 0.0024799052625894547\n",
      "step: 210, task: Structured/Beer, loss: 0.051350485533475876\n",
      "step: 220, task: Structured/Beer, loss: 0.002198757603764534\n",
      "step: 230, task: Structured/Beer, loss: 0.00254032202064991\n",
      "step: 240, task: Structured/Beer, loss: 0.0024924352765083313\n",
      "step: 250, task: Structured/Beer, loss: 0.04944688826799393\n",
      "step: 260, task: Structured/Beer, loss: 0.002786511555314064\n",
      "step: 270, task: Structured/Beer, loss: 0.002419091761112213\n",
      "step: 280, task: Structured/Beer, loss: 0.0020266342908143997\n",
      "step: 290, task: Structured/Beer, loss: 0.002204054966568947\n",
      "step: 300, task: Structured/Beer, loss: 0.001999625936150551\n",
      "step: 310, task: Structured/Beer, loss: 0.0018774010241031647\n",
      "step: 320, task: Structured/Beer, loss: 0.0015071891248226166\n",
      "step: 330, task: Structured/Beer, loss: 0.0016485396772623062\n",
      "step: 340, task: Structured/Beer, loss: 0.004101032391190529\n",
      "step: 350, task: Structured/Beer, loss: 0.004096253775060177\n",
      "step: 360, task: Structured/Beer, loss: 0.0026693474501371384\n",
      "step: 370, task: Structured/Beer, loss: 0.0019971169531345367\n",
      "step: 380, task: Structured/Beer, loss: 0.04220772162079811\n",
      "step: 390, task: Structured/Beer, loss: 0.002643570303916931\n",
      "step: 400, task: Structured/Beer, loss: 0.0020046941936016083\n",
      "step: 410, task: Structured/Beer, loss: 0.0014859214425086975\n",
      "step: 420, task: Structured/Beer, loss: 0.0013471171259880066\n",
      "step: 430, task: Structured/Beer, loss: 0.0014980211853981018\n",
      "step: 440, task: Structured/Beer, loss: 0.05090763047337532\n",
      "step: 450, task: Structured/Beer, loss: 0.0036727488040924072\n",
      "step: 460, task: Structured/Beer, loss: 0.003519345074892044\n",
      "step: 470, task: Structured/Beer, loss: 0.0475812703371048\n",
      "step: 480, task: Structured/Beer, loss: 0.002765849232673645\n",
      "step: 490, task: Structured/Beer, loss: 0.00214431993663311\n",
      "step: 500, task: Structured/Beer, loss: 0.09972172975540161\n",
      "step: 510, task: Structured/Beer, loss: 0.0027077682316303253\n",
      "step: 520, task: Structured/Beer, loss: 0.003737853839993477\n",
      "step: 530, task: Structured/Beer, loss: 0.002074381336569786\n",
      "step: 540, task: Structured/Beer, loss: 0.002511521801352501\n",
      "step: 550, task: Structured/Beer, loss: 0.002383517101407051\n",
      "step: 560, task: Structured/Beer, loss: 0.0017417259514331818\n",
      "step: 570, task: Structured/Beer, loss: 0.0011104904115200043\n",
      "step: 580, task: Structured/Beer, loss: 0.0010746232001110911\n",
      "step: 590, task: Structured/Beer, loss: 0.0018099267035722733\n",
      "step: 600, task: Structured/Beer, loss: 0.0035648103803396225\n",
      "step: 610, task: Structured/Beer, loss: 0.0025768671184778214\n",
      "step: 620, task: Structured/Beer, loss: 0.0015047695487737656\n",
      "step: 630, task: Structured/Beer, loss: 0.0009188447147607803\n",
      "step: 640, task: Structured/Beer, loss: 0.0014968141913414001\n",
      "step: 650, task: Structured/Beer, loss: 0.0033736303448677063\n",
      "step: 660, task: Structured/Beer, loss: 0.0019180644303560257\n",
      "step: 670, task: Structured/Beer, loss: 0.0024433601647615433\n",
      "step: 680, task: Structured/Beer, loss: 0.0010487940162420273\n",
      "step: 690, task: Structured/Beer, loss: 0.0006355661898851395\n",
      "step: 700, task: Structured/Beer, loss: 0.0006053243414498866\n",
      "step: 710, task: Structured/Beer, loss: 0.053243719041347504\n",
      "step: 720, task: Structured/Beer, loss: 0.0031196214258670807\n",
      "step: 730, task: Structured/Beer, loss: 0.05209202319383621\n",
      "step: 740, task: Structured/Beer, loss: 0.002208622172474861\n",
      "step: 750, task: Structured/Beer, loss: 0.04662758857011795\n",
      "step: 760, task: Structured/Beer, loss: 0.0013776440173387527\n",
      "step: 770, task: Structured/Beer, loss: 0.04622618108987808\n",
      "step: 780, task: Structured/Beer, loss: 0.003684036433696747\n",
      "step: 790, task: Structured/Beer, loss: 0.0011555030941963196\n",
      "step: 800, task: Structured/Beer, loss: 0.057433903217315674\n",
      "step: 810, task: Structured/Beer, loss: 0.0009147785604000092\n",
      "step: 820, task: Structured/Beer, loss: 0.0013283435255289078\n",
      "step: 830, task: Structured/Beer, loss: 0.001559332013130188\n",
      "step: 840, task: Structured/Beer, loss: 0.0018557645380496979\n",
      "step: 850, task: Structured/Beer, loss: 0.0025719478726387024\n",
      "step: 860, task: Structured/Beer, loss: 0.0014600232243537903\n",
      "step: 870, task: Structured/Beer, loss: 0.0013669133186340332\n",
      "step: 880, task: Structured/Beer, loss: 0.0017798133194446564\n",
      "step: 890, task: Structured/Beer, loss: 0.09725470840930939\n",
      "step: 900, task: Structured/Beer, loss: 0.0068853553384542465\n",
      "step: 910, task: Structured/Beer, loss: 0.001714935526251793\n",
      "step: 920, task: Structured/Beer, loss: 0.0007512085139751434\n",
      "step: 930, task: Structured/Beer, loss: 0.0008929520845413208\n",
      "step: 940, task: Structured/Beer, loss: 0.0012364517897367477\n",
      "step: 950, task: Structured/Beer, loss: 0.051566001027822495\n",
      "step: 960, task: Structured/Beer, loss: 0.0027107931673526764\n",
      "step: 970, task: Structured/Beer, loss: 0.003330651670694351\n",
      "step: 980, task: Structured/Beer, loss: 0.0022218339145183563\n",
      "step: 990, task: Structured/Beer, loss: 0.0014480482786893845\n",
      "step: 1000, task: Structured/Beer, loss: 0.0010348949581384659\n",
      "step: 1010, task: Structured/Beer, loss: 0.0009659156203269958\n",
      "step: 1020, task: Structured/Beer, loss: 0.0017123650759458542\n",
      "step: 1030, task: Structured/Beer, loss: 0.0038457252085208893\n",
      "step: 1040, task: Structured/Beer, loss: 0.0025527402758598328\n",
      "step: 1050, task: Structured/Beer, loss: 0.055214621126651764\n",
      "step: 1060, task: Structured/Beer, loss: 0.0009275004849769175\n",
      "step: 1070, task: Structured/Beer, loss: 0.0011370796710252762\n",
      "step: 1080, task: Structured/Beer, loss: 0.0014253314584493637\n",
      "step: 1090, task: Structured/Beer, loss: 0.0017641857266426086\n",
      "step: 1100, task: Structured/Beer, loss: 0.0037528909742832184\n",
      "step: 1110, task: Structured/Beer, loss: 0.0032674819231033325\n",
      "step: 1120, task: Structured/Beer, loss: 0.00224931538105011\n",
      "step: 1130, task: Structured/Beer, loss: 0.052468717098236084\n",
      "step: 1140, task: Structured/Beer, loss: 0.001452915370464325\n",
      "step: 1150, task: Structured/Beer, loss: 0.052849747240543365\n",
      "step: 1160, task: Structured/Beer, loss: 0.0017654243856668472\n",
      "step: 1170, task: Structured/Beer, loss: 0.0024956632405519485\n",
      "step: 1180, task: Structured/Beer, loss: 0.005158701911568642\n",
      "step: 1190, task: Structured/Beer, loss: 0.003979375585913658\n",
      "step: 1200, task: Structured/Beer, loss: 0.002919415244832635\n",
      "step: 1210, task: Structured/Beer, loss: 0.002707265317440033\n",
      "step: 1220, task: Structured/Beer, loss: 0.006153753958642483\n",
      "step: 1230, task: Structured/Beer, loss: 0.004386487416923046\n",
      "step: 1240, task: Structured/Beer, loss: 0.0032851379364728928\n",
      "step: 1250, task: Structured/Beer, loss: 0.05263042077422142\n",
      "step: 1260, task: Structured/Beer, loss: 0.0023780129849910736\n",
      "step: 1270, task: Structured/Beer, loss: 0.04144800454378128\n",
      "step: 1280, task: Structured/Beer, loss: 0.04722043499350548\n",
      "step: 1290, task: Structured/Beer, loss: 0.0011428110301494598\n",
      "step: 1300, task: Structured/Beer, loss: 0.001389944925904274\n",
      "step: 1310, task: Structured/Beer, loss: 0.04489000514149666\n",
      "step: 1320, task: Structured/Beer, loss: 0.051451727747917175\n",
      "step: 1330, task: Structured/Beer, loss: 0.08866247534751892\n",
      "step: 1340, task: Structured/Beer, loss: 0.002649344503879547\n",
      "step: 1350, task: Structured/Beer, loss: 0.0016251299530267715\n",
      "step: 1360, task: Structured/Beer, loss: 0.0014887172728776932\n",
      "step: 1370, task: Structured/Beer, loss: 0.0012337006628513336\n",
      "step: 1380, task: Structured/Beer, loss: 0.0031007369980216026\n",
      "step: 1390, task: Structured/Beer, loss: 0.002453591674566269\n",
      "step: 1400, task: Structured/Beer, loss: 0.032172463834285736\n",
      "step: 1410, task: Structured/Beer, loss: 0.0040331874042749405\n",
      "step: 1420, task: Structured/Beer, loss: 0.0006920509040355682\n",
      "step: 1430, task: Structured/Beer, loss: 0.001032121479511261\n",
      "step: 1440, task: Structured/Beer, loss: 0.0016349256038665771\n",
      "step: 1450, task: Structured/Beer, loss: 0.0015628207474946976\n",
      "step: 1460, task: Structured/Beer, loss: 0.007428973447531462\n",
      "step: 1470, task: Structured/Beer, loss: 0.0021994831040501595\n",
      "step: 1480, task: Structured/Beer, loss: 0.04378967359662056\n",
      "step: 1490, task: Structured/Beer, loss: 0.0025436412543058395\n",
      "step: 1500, task: Structured/Beer, loss: 0.0013084746897220612\n",
      "step: 1510, task: Structured/Beer, loss: 0.04113190248608589\n",
      "step: 1520, task: Structured/Beer, loss: 0.0018177349120378494\n",
      "step: 1530, task: Structured/Beer, loss: 0.0019822288304567337\n",
      "step: 1540, task: Structured/Beer, loss: 0.002703222446143627\n",
      "step: 1550, task: Structured/Beer, loss: 0.048062875866889954\n",
      "step: 1560, task: Structured/Beer, loss: 0.09118601679801941\n",
      "step: 1570, task: Structured/Beer, loss: 0.0027482612058520317\n",
      "step: 1580, task: Structured/Beer, loss: 0.002488396130502224\n",
      "step: 1590, task: Structured/Beer, loss: 0.001219564932398498\n",
      "step: 1600, task: Structured/Beer, loss: 0.0014028456062078476\n",
      "step: 1610, task: Structured/Beer, loss: 0.0024099107831716537\n",
      "step: 1620, task: Structured/Beer, loss: 0.0020564189180731773\n",
      "step: 1630, task: Structured/Beer, loss: 0.062298230826854706\n",
      "step: 1640, task: Structured/Beer, loss: 0.0007415898144245148\n",
      "step: 1650, task: Structured/Beer, loss: 0.0010148808360099792\n",
      "step: 1660, task: Structured/Beer, loss: 0.0007175263017416\n",
      "step: 1670, task: Structured/Beer, loss: 0.06275255978107452\n",
      "step: 1680, task: Structured/Beer, loss: 0.0007235705852508545\n",
      "step: 1690, task: Structured/Beer, loss: 0.0009299572557210922\n",
      "step: 1700, task: Structured/Beer, loss: 0.002332888310775161\n",
      "step: 1710, task: Structured/Beer, loss: 0.05724306404590607\n",
      "step: 1720, task: Structured/Beer, loss: 0.1076117530465126\n",
      "step: 1730, task: Structured/Beer, loss: 0.0012084506452083588\n",
      "step: 1740, task: Structured/Beer, loss: 0.0012210682034492493\n",
      "step: 1750, task: Structured/Beer, loss: 0.0011789314448833466\n",
      "step: 1760, task: Structured/Beer, loss: 0.0017194785177707672\n",
      "step: 1770, task: Structured/Beer, loss: 0.04361579939723015\n",
      "step: 1780, task: Structured/Beer, loss: 0.002570818178355694\n",
      "step: 1790, task: Structured/Beer, loss: 0.09677866101264954\n",
      "step: 1800, task: Structured/Beer, loss: 0.0034991002175956964\n",
      "step: 1810, task: Structured/Beer, loss: 0.002716389484703541\n",
      "step: 1820, task: Structured/Beer, loss: 0.003887411206960678\n",
      "step: 1830, task: Structured/Beer, loss: 0.04214634373784065\n",
      "step: 1840, task: Structured/Beer, loss: 0.0008799564093351364\n",
      "step: 1850, task: Structured/Beer, loss: 0.0008417274802923203\n",
      "step: 1860, task: Structured/Beer, loss: 0.00244099460542202\n",
      "step: 1870, task: Structured/Beer, loss: 0.010935639031231403\n",
      "step: 1880, task: Structured/Beer, loss: 0.06116602197289467\n",
      "step: 1890, task: Structured/Beer, loss: 0.0009163860231637955\n",
      "step: 1900, task: Structured/Beer, loss: 0.001647626981139183\n",
      "step: 1910, task: Structured/Beer, loss: 0.0007562953978776932\n",
      "step: 1920, task: Structured/Beer, loss: 0.056386351585388184\n",
      "step: 1930, task: Structured/Beer, loss: 0.0007671080529689789\n",
      "step: 1940, task: Structured/Beer, loss: 0.0009526442736387253\n",
      "step: 1950, task: Structured/Beer, loss: 0.0009582024067640305\n",
      "step: 1960, task: Structured/Beer, loss: 0.0036189709790050983\n",
      "step: 1970, task: Structured/Beer, loss: 0.006509076803922653\n",
      "step: 1980, task: Structured/Beer, loss: 0.0009622983634471893\n",
      "step: 1990, task: Structured/Beer, loss: 0.000986531376838684\n",
      "step: 2000, task: Structured/Beer, loss: 0.005118575878441334\n",
      "step: 2010, task: Structured/Beer, loss: 0.002960848854854703\n",
      "step: 2020, task: Structured/Beer, loss: 0.0009094551205635071\n",
      "step: 2030, task: Structured/Beer, loss: 0.0008660797029733658\n",
      "step: 2040, task: Structured/Beer, loss: 0.043562423437833786\n",
      "step: 2050, task: Structured/Beer, loss: 0.0035853851586580276\n",
      "step: 2060, task: Structured/Beer, loss: 0.004111062735319138\n",
      "step: 2070, task: Structured/Beer, loss: 0.0017059603706002235\n",
      "step: 2080, task: Structured/Beer, loss: 0.001630864106118679\n",
      "step: 2090, task: Structured/Beer, loss: 0.00262334942817688\n",
      "step: 2100, task: Structured/Beer, loss: 0.03930740803480148\n",
      "step: 2110, task: Structured/Beer, loss: 0.053657714277505875\n",
      "step: 2120, task: Structured/Beer, loss: 0.004190979525446892\n",
      "step: 2130, task: Structured/Beer, loss: 0.0011975206434726715\n",
      "step: 2140, task: Structured/Beer, loss: 0.0012041701702401042\n",
      "step: 2150, task: Structured/Beer, loss: 0.0020155981183052063\n",
      "step: 2160, task: Structured/Beer, loss: 0.0016785738989710808\n",
      "step: 2170, task: Structured/Beer, loss: 0.003231436014175415\n",
      "step: 2180, task: Structured/Beer, loss: 0.0012845462188124657\n",
      "step: 2190, task: Structured/Beer, loss: 0.0008986741304397583\n",
      "step: 2200, task: Structured/Beer, loss: 0.0007957480847835541\n",
      "step: 2210, task: Structured/Beer, loss: 0.000493224710226059\n",
      "step: 2220, task: Structured/Beer, loss: 0.000540565699338913\n",
      "step: 2230, task: Structured/Beer, loss: 0.05802756920456886\n",
      "step: 2240, task: Structured/Beer, loss: 0.0006497614085674286\n",
      "step: 2250, task: Structured/Beer, loss: 0.0025528473779559135\n",
      "step: 2260, task: Structured/Beer, loss: 0.0007638921961188316\n",
      "step: 2270, task: Structured/Beer, loss: 0.0006681680679321289\n",
      "step: 2280, task: Structured/Beer, loss: 0.002129442524164915\n",
      "step: 2290, task: Structured/Beer, loss: 0.0005410145386122167\n",
      "step: 2300, task: Structured/Beer, loss: 0.0008233468979597092\n",
      "step: 2310, task: Structured/Beer, loss: 0.002502165734767914\n",
      "step: 2320, task: Structured/Beer, loss: 0.000786755234003067\n",
      "step: 2330, task: Structured/Beer, loss: 0.002583811990916729\n",
      "step: 2340, task: Structured/Beer, loss: 0.02702268213033676\n",
      "step: 2350, task: Structured/Beer, loss: 0.001057351939380169\n",
      "step: 2360, task: Structured/Beer, loss: 0.059488680213689804\n",
      "step: 2370, task: Structured/Beer, loss: 0.002058120444417\n",
      "step: 2380, task: Structured/Beer, loss: 0.06080044060945511\n",
      "step: 2390, task: Structured/Beer, loss: 0.056324224919080734\n",
      "step: 2400, task: Structured/Beer, loss: 0.0015584984794259071\n",
      "step: 2410, task: Structured/Beer, loss: 0.0007709991186857224\n",
      "step: 2420, task: Structured/Beer, loss: 0.0007682926952838898\n",
      "step: 2430, task: Structured/Beer, loss: 0.000696057453751564\n",
      "step: 2440, task: Structured/Beer, loss: 0.0008152090013027191\n",
      "step: 2450, task: Structured/Beer, loss: 0.013187145814299583\n",
      "step: 2460, task: Structured/Beer, loss: 0.000786893127951771\n",
      "step: 2470, task: Structured/Beer, loss: 0.001570509746670723\n",
      "step: 2480, task: Structured/Beer, loss: 0.0020561479032039642\n",
      "step: 2490, task: Structured/Beer, loss: 0.05168967694044113\n",
      "step: 2500, task: Structured/Beer, loss: 0.0023004822432994843\n",
      "step: 2510, task: Structured/Beer, loss: 0.002052176743745804\n",
      "step: 2520, task: Structured/Beer, loss: 0.007177059538662434\n",
      "step: 2530, task: Structured/Beer, loss: 0.008534260094165802\n",
      "step: 2540, task: Structured/Beer, loss: 0.004219593480229378\n",
      "step: 2550, task: Structured/Beer, loss: 0.0022109407000243664\n",
      "step: 2560, task: Structured/Beer, loss: 0.0010286467149853706\n",
      "step: 2570, task: Structured/Beer, loss: 0.05576932430267334\n",
      "step: 2580, task: Structured/Beer, loss: 0.0012787003070116043\n",
      "step: 2590, task: Structured/Beer, loss: 0.0018236702308058739\n",
      "step: 2600, task: Structured/Beer, loss: 0.009473578073084354\n",
      "step: 2610, task: Structured/Beer, loss: 0.0052166529931128025\n",
      "step: 2620, task: Structured/Beer, loss: 0.0018778527155518532\n",
      "step: 2630, task: Structured/Beer, loss: 0.001521890051662922\n",
      "step: 2640, task: Structured/Beer, loss: 0.0010336320847272873\n",
      "step: 2650, task: Structured/Beer, loss: 0.05554959177970886\n",
      "step: 2660, task: Structured/Beer, loss: 0.0019248584285378456\n",
      "step: 2670, task: Structured/Beer, loss: 0.05024682730436325\n",
      "step: 2680, task: Structured/Beer, loss: 0.0028754640370607376\n",
      "step: 2690, task: Structured/Beer, loss: 0.0019023959757760167\n",
      "step: 2700, task: Structured/Beer, loss: 0.0028874147683382034\n",
      "step: 2710, task: Structured/Beer, loss: 0.001144525595009327\n",
      "step: 2720, task: Structured/Beer, loss: 0.002235020510852337\n",
      "step: 2730, task: Structured/Beer, loss: 0.001329144462943077\n",
      "step: 2740, task: Structured/Beer, loss: 0.002485858276486397\n",
      "step: 2750, task: Structured/Beer, loss: 0.002833060920238495\n",
      "step: 2760, task: Structured/Beer, loss: 0.0005678907036781311\n",
      "step: 2770, task: Structured/Beer, loss: 0.0005018822848796844\n",
      "step: 2780, task: Structured/Beer, loss: 0.0006807353929616511\n",
      "step: 2790, task: Structured/Beer, loss: 0.009915325790643692\n",
      "step: 2800, task: Structured/Beer, loss: 0.004169458989053965\n",
      "step: 2810, task: Structured/Beer, loss: 0.001570357009768486\n",
      "step: 2820, task: Structured/Beer, loss: 0.05581635236740112\n",
      "step: 2830, task: Structured/Beer, loss: 0.0019444078207015991\n",
      "step: 2840, task: Structured/Beer, loss: 0.004787244834005833\n",
      "step: 2850, task: Structured/Beer, loss: 0.0013228598982095718\n",
      "step: 2860, task: Structured/Beer, loss: 0.0009089168161153793\n",
      "step: 2870, task: Structured/Beer, loss: 0.05546606332063675\n",
      "step: 2880, task: Structured/Beer, loss: 0.0010438952594995499\n",
      "step: 2890, task: Structured/Beer, loss: 0.002464350312948227\n",
      "step: 2900, task: Structured/Beer, loss: 0.005923514254391193\n",
      "step: 2910, task: Structured/Beer, loss: 0.010678542777895927\n",
      "step: 2920, task: Structured/Beer, loss: 0.006968989036977291\n",
      "step: 2930, task: Structured/Beer, loss: 0.0478297658264637\n",
      "step: 2940, task: Structured/Beer, loss: 0.0011802716180682182\n",
      "step: 2950, task: Structured/Beer, loss: 0.01054183579981327\n",
      "step: 2960, task: Structured/Beer, loss: 0.0003263503313064575\n",
      "step: 2970, task: Structured/Beer, loss: 0.0007023364305496216\n",
      "step: 2980, task: Structured/Beer, loss: 0.011021406389772892\n",
      "step: 2990, task: Structured/Beer, loss: 0.0005019586533308029\n",
      "step: 3000, task: Structured/Beer, loss: 0.0004666801542043686\n",
      "step: 3010, task: Structured/Beer, loss: 0.0005262233316898346\n",
      "step: 3020, task: Structured/Beer, loss: 0.0007104650139808655\n",
      "step: 3030, task: Structured/Beer, loss: 0.0013669896870851517\n",
      "step: 3040, task: Structured/Beer, loss: 0.002251729369163513\n",
      "step: 3050, task: Structured/Beer, loss: 0.002473309636116028\n",
      "step: 3060, task: Structured/Beer, loss: 0.0015417189570143819\n",
      "=========eval at epoch=1=========\n",
      "Validation:\n",
      "=============Structured/Beer==================\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "accuracy=0.998\n",
      "precision=0.000\n",
      "recall=0.000\n",
      "f1=0.000\n",
      "======================================\n",
      "Test:\n",
      "=============Structured/Beer==================\n",
      "accuracy=0.998\n",
      "precision=0.000\n",
      "recall=0.000\n",
      "f1=0.000\n",
      "======================================\n",
      "=====sanity check======\n",
      "words: COL movie VAL anupam kher steven mackintosh madhavan color not rated rakeysh omprakash mehra hindi india  2006 [SEP] COL movie VAL \"I used to think this was the beginning of your story.... We're so bound by time\", Dr. Louise Banks said within the first 30 seconds of the film. Little did I know upon my first viewing that this was the true theme of the whole movie.Arrival to its core is about the power of language, and how much language shapes who we are, what we think, how we see the world around us, etc. When the alien race comes to earth Dr. Banks is tasked with discovering their language and how to communicate with them to understand why they're here. As she learns more she discovers that they don't think like we think, or communicate like we communicate. She discovers the aliens are not bound by time as the humans are, and encourages Dr. Banks to use \"the weapon\".There's dialogue between Ian and Dr. Banks halfway through the film where they discuss the Sapir-Whorf hypothesis, which essentially means if you study a foreign language long enough you can rewire your brain; that the language you speak determines how you think. As Dr. Banks learns more of this alien language she begins acquiring the knowledge to think how they think - which is non-linear, unbound by time.This theme is present through the whole movie: from her daughter, to the spelling of her daughters name, Hannah (makes more sense upon viewing the film), to the big reveal at the end.But the true beauty is that the farther the viewer goes and acquires the knowledge along with Dr. Banks, we too understand that the story itself is non-linear - the beginning of the movie is actually the end. We see the beginning and think it's the beginning as you normally do, but as we become immersed and follow Dr. Banks, learning what she learns, we too become set free by time.The question is: if you knew your life from beginning to end, would you change anything? This movie is more than an alien invasion, which we've seen a thousand times. It's much deeper than that, and should be appreciated as such. Arrival showcases the art of storytelling.Easily a 10/10\n",
      "x: [  101  8902  3185 11748  2019  6279  3286  1047  5886  7112 11349 18447\n",
      " 17369  5506 24652  3609  2025  6758 26008  7274  2232 18168 18098 11905\n",
      "  4095  2033 13492  9269  2634  2294   102  8902  3185 11748  1000  1045\n",
      "  2109  2000  2228  2023  2001  1996  2927  1997  2115  2466  1012  1012\n",
      "  1012  1012  2057  1005  2128  2061  5391  2011  2051  1000  1010  2852\n",
      "  1012  8227  5085  2056  2306  1996  2034  2382  3823  1997  1996  2143\n",
      "  1012  2210  2106  1045  2113  2588  2026  2034 10523  2008  2023  2001\n",
      "  1996  2995  4323  1997  1996  2878  3185  1012  5508  2000  2049  4563\n",
      "  2003  2055  1996  2373  1997  2653  1010  1998  2129  2172  2653 10466\n",
      "  2040  2057  2024  1010  2054  2057  2228  1010  2129  2057  2156  1996\n",
      "  2088  2105  2149  1010  4385  1012  2043   102]\n",
      "tokens: ['[CLS]', 'col', 'movie', 'val', 'an', '##up', '##am', 'k', '##her', 'steven', 'mack', '##int', '##osh', 'mad', '##havan', 'color', 'not', 'rated', 'rake', '##ys', '##h', 'om', '##pr', '##aka', '##sh', 'me', '##hra', 'hindi', 'india', '2006', '[SEP]', 'col', 'movie', 'val', '\"', 'i', 'used', 'to', 'think', 'this', 'was', 'the', 'beginning', 'of', 'your', 'story', '.', '.', '.', '.', 'we', \"'\", 're', 'so', 'bound', 'by', 'time', '\"', ',', 'dr', '.', 'louise', 'banks', 'said', 'within', 'the', 'first', '30', 'seconds', 'of', 'the', 'film', '.', 'little', 'did', 'i', 'know', 'upon', 'my', 'first', 'viewing', 'that', 'this', 'was', 'the', 'true', 'theme', 'of', 'the', 'whole', 'movie', '.', 'arrival', 'to', 'its', 'core', 'is', 'about', 'the', 'power', 'of', 'language', ',', 'and', 'how', 'much', 'language', 'shapes', 'who', 'we', 'are', ',', 'what', 'we', 'think', ',', 'how', 'we', 'see', 'the', 'world', 'around', 'us', ',', 'etc', '.', 'when', '[SEP]']\n",
      "is_heads: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "y: 0\n",
      "tags: 0\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "seqlen: 128\n",
      "task_name: Structured/Beer\n",
      "=======================\n",
      "step: 0, task: Structured/Beer, loss: 0.0019943425431847572\n",
      "step: 10, task: Structured/Beer, loss: 0.04927759990096092\n",
      "step: 20, task: Structured/Beer, loss: 0.00148764718323946\n",
      "step: 30, task: Structured/Beer, loss: 0.010904185473918915\n",
      "step: 40, task: Structured/Beer, loss: 0.05027471482753754\n",
      "step: 50, task: Structured/Beer, loss: 0.0025224797427654266\n",
      "step: 60, task: Structured/Beer, loss: 0.0011668894439935684\n",
      "step: 70, task: Structured/Beer, loss: 0.03135187178850174\n",
      "step: 80, task: Structured/Beer, loss: 0.003175429068505764\n",
      "step: 90, task: Structured/Beer, loss: 0.0013805506750941277\n",
      "step: 100, task: Structured/Beer, loss: 0.020555924624204636\n",
      "step: 110, task: Structured/Beer, loss: 0.004027309361845255\n",
      "step: 120, task: Structured/Beer, loss: 0.001203468069434166\n",
      "step: 130, task: Structured/Beer, loss: 0.0008745081722736359\n",
      "step: 140, task: Structured/Beer, loss: 0.000925133004784584\n",
      "step: 150, task: Structured/Beer, loss: 0.055315472185611725\n",
      "step: 160, task: Structured/Beer, loss: 0.0007742717862129211\n",
      "step: 170, task: Structured/Beer, loss: 0.000858839601278305\n",
      "step: 180, task: Structured/Beer, loss: 0.0014266055077314377\n",
      "step: 190, task: Structured/Beer, loss: 0.0026791079435497522\n",
      "step: 200, task: Structured/Beer, loss: 0.0019163237884640694\n",
      "step: 210, task: Structured/Beer, loss: 0.10560037940740585\n",
      "step: 220, task: Structured/Beer, loss: 0.0011903857812285423\n",
      "step: 230, task: Structured/Beer, loss: 0.0022941187489777803\n",
      "step: 240, task: Structured/Beer, loss: 0.004677168093621731\n",
      "step: 250, task: Structured/Beer, loss: 0.0005308631807565689\n",
      "step: 260, task: Structured/Beer, loss: 0.007554507814347744\n",
      "step: 270, task: Structured/Beer, loss: 0.0005144085735082626\n",
      "step: 280, task: Structured/Beer, loss: 0.0015250016003847122\n",
      "step: 290, task: Structured/Beer, loss: 0.00929529219865799\n",
      "step: 300, task: Structured/Beer, loss: 0.013066444545984268\n",
      "step: 310, task: Structured/Beer, loss: 0.003712634090334177\n",
      "step: 320, task: Structured/Beer, loss: 0.0009414143860340118\n",
      "step: 330, task: Structured/Beer, loss: 0.0005069170147180557\n",
      "step: 340, task: Structured/Beer, loss: 0.015023562125861645\n",
      "step: 350, task: Structured/Beer, loss: 0.0004175938665866852\n",
      "step: 360, task: Structured/Beer, loss: 0.0009069805964827538\n",
      "step: 370, task: Structured/Beer, loss: 0.01818178780376911\n",
      "step: 380, task: Structured/Beer, loss: 0.0017406269907951355\n",
      "step: 390, task: Structured/Beer, loss: 0.05132710933685303\n",
      "step: 400, task: Structured/Beer, loss: 0.0009953603148460388\n",
      "step: 410, task: Structured/Beer, loss: 0.002827810123562813\n",
      "step: 420, task: Structured/Beer, loss: 0.0016783643513917923\n",
      "step: 430, task: Structured/Beer, loss: 0.0012755291536450386\n",
      "step: 440, task: Structured/Beer, loss: 0.0027366196736693382\n",
      "step: 450, task: Structured/Beer, loss: 0.0005675051361322403\n",
      "step: 460, task: Structured/Beer, loss: 0.00038827210664749146\n",
      "step: 470, task: Structured/Beer, loss: 0.00045641325414180756\n",
      "step: 480, task: Structured/Beer, loss: 0.0016777943819761276\n",
      "step: 490, task: Structured/Beer, loss: 0.0559244267642498\n",
      "step: 500, task: Structured/Beer, loss: 0.00051141157746315\n",
      "step: 510, task: Structured/Beer, loss: 0.0005135275423526764\n",
      "step: 520, task: Structured/Beer, loss: 0.0004226267628837377\n",
      "step: 530, task: Structured/Beer, loss: 0.0004422552592586726\n",
      "step: 540, task: Structured/Beer, loss: 0.014867995865643024\n",
      "step: 550, task: Structured/Beer, loss: 0.0009074266999959946\n",
      "step: 560, task: Structured/Beer, loss: 0.0012525562196969986\n",
      "step: 570, task: Structured/Beer, loss: 0.009754853323101997\n",
      "step: 580, task: Structured/Beer, loss: 0.05946562439203262\n",
      "step: 590, task: Structured/Beer, loss: 0.005211623385548592\n",
      "step: 600, task: Structured/Beer, loss: 0.001874491572380066\n",
      "step: 610, task: Structured/Beer, loss: 0.0019300542771816254\n",
      "step: 620, task: Structured/Beer, loss: 0.001351071521639824\n",
      "step: 630, task: Structured/Beer, loss: 0.001990530639886856\n",
      "step: 640, task: Structured/Beer, loss: 0.0015001101419329643\n",
      "step: 650, task: Structured/Beer, loss: 0.003151440527290106\n",
      "step: 660, task: Structured/Beer, loss: 0.002167241647839546\n",
      "step: 670, task: Structured/Beer, loss: 0.005773792043328285\n",
      "step: 680, task: Structured/Beer, loss: 0.0013838076265528798\n",
      "step: 690, task: Structured/Beer, loss: 0.0010415613651275635\n",
      "step: 700, task: Structured/Beer, loss: 0.0009475052356719971\n",
      "step: 710, task: Structured/Beer, loss: 0.002264084294438362\n",
      "step: 720, task: Structured/Beer, loss: 0.0018531586974859238\n",
      "step: 730, task: Structured/Beer, loss: 0.0038884193636476994\n",
      "step: 740, task: Structured/Beer, loss: 0.00124305859208107\n",
      "step: 750, task: Structured/Beer, loss: 0.0009390581399202347\n",
      "step: 760, task: Structured/Beer, loss: 0.05016715079545975\n",
      "step: 770, task: Structured/Beer, loss: 0.01662077009677887\n",
      "step: 780, task: Structured/Beer, loss: 0.0069619896821677685\n",
      "step: 790, task: Structured/Beer, loss: 0.05196557939052582\n",
      "step: 800, task: Structured/Beer, loss: 0.0007417872548103333\n",
      "step: 810, task: Structured/Beer, loss: 0.0006692633614875376\n",
      "step: 820, task: Structured/Beer, loss: 0.0011060815304517746\n",
      "step: 830, task: Structured/Beer, loss: 0.002645531203597784\n",
      "step: 840, task: Structured/Beer, loss: 0.0007596807554364204\n",
      "step: 850, task: Structured/Beer, loss: 0.0007507530972361565\n",
      "step: 860, task: Structured/Beer, loss: 0.003647174686193466\n",
      "step: 870, task: Structured/Beer, loss: 0.001619995222426951\n",
      "step: 880, task: Structured/Beer, loss: 0.048902727663517\n",
      "step: 890, task: Structured/Beer, loss: 0.003558566328138113\n",
      "step: 900, task: Structured/Beer, loss: 0.0032444451935589314\n",
      "step: 910, task: Structured/Beer, loss: 0.019725536927580833\n",
      "step: 920, task: Structured/Beer, loss: 0.0016493937000632286\n",
      "step: 930, task: Structured/Beer, loss: 0.0011850930750370026\n",
      "step: 940, task: Structured/Beer, loss: 0.009157758206129074\n",
      "step: 950, task: Structured/Beer, loss: 0.0007673930376768112\n",
      "step: 960, task: Structured/Beer, loss: 0.013501999899744987\n",
      "step: 970, task: Structured/Beer, loss: 0.06030682474374771\n",
      "step: 980, task: Structured/Beer, loss: 0.0008419584482908249\n",
      "step: 990, task: Structured/Beer, loss: 0.0012247487902641296\n",
      "step: 1000, task: Structured/Beer, loss: 0.0006056614220142365\n",
      "step: 1010, task: Structured/Beer, loss: 0.0010858067544177175\n",
      "step: 1020, task: Structured/Beer, loss: 0.05501259118318558\n",
      "step: 1030, task: Structured/Beer, loss: 0.0006700996309518814\n",
      "step: 1040, task: Structured/Beer, loss: 0.0007554404437541962\n",
      "step: 1050, task: Structured/Beer, loss: 0.0009311195462942123\n",
      "step: 1060, task: Structured/Beer, loss: 0.0006297342479228973\n",
      "step: 1070, task: Structured/Beer, loss: 0.0008934829384088516\n",
      "step: 1080, task: Structured/Beer, loss: 0.006291570141911507\n",
      "step: 1090, task: Structured/Beer, loss: 0.0008450672612525523\n",
      "step: 1100, task: Structured/Beer, loss: 0.002682761289179325\n",
      "step: 1110, task: Structured/Beer, loss: 0.001260535791516304\n",
      "step: 1120, task: Structured/Beer, loss: 0.001141396351158619\n",
      "step: 1130, task: Structured/Beer, loss: 0.0015700720250606537\n",
      "step: 1140, task: Structured/Beer, loss: 0.0021899277344346046\n",
      "step: 1150, task: Structured/Beer, loss: 0.0031791902147233486\n",
      "step: 1160, task: Structured/Beer, loss: 0.0019549503922462463\n",
      "step: 1170, task: Structured/Beer, loss: 0.0017024027183651924\n",
      "step: 1180, task: Structured/Beer, loss: 0.01602267287671566\n",
      "step: 1190, task: Structured/Beer, loss: 0.0006061438471078873\n",
      "step: 1200, task: Structured/Beer, loss: 0.0006653759628534317\n",
      "step: 1210, task: Structured/Beer, loss: 0.0006063040345907211\n",
      "step: 1220, task: Structured/Beer, loss: 0.0005491748452186584\n",
      "step: 1230, task: Structured/Beer, loss: 0.06920234113931656\n",
      "step: 1240, task: Structured/Beer, loss: 0.00036673620343208313\n",
      "step: 1250, task: Structured/Beer, loss: 0.06629792600870132\n",
      "step: 1260, task: Structured/Beer, loss: 0.00045305676758289337\n",
      "step: 1270, task: Structured/Beer, loss: 0.00033794716000556946\n",
      "step: 1280, task: Structured/Beer, loss: 0.06348420679569244\n",
      "step: 1290, task: Structured/Beer, loss: 0.0016765417531132698\n",
      "step: 1300, task: Structured/Beer, loss: 0.0013001756742596626\n",
      "step: 1310, task: Structured/Beer, loss: 0.003528342582285404\n",
      "step: 1320, task: Structured/Beer, loss: 0.0019191354513168335\n",
      "step: 1330, task: Structured/Beer, loss: 0.011575523763895035\n",
      "step: 1340, task: Structured/Beer, loss: 0.012487983331084251\n",
      "step: 1350, task: Structured/Beer, loss: 0.0019333269447088242\n",
      "step: 1360, task: Structured/Beer, loss: 0.05109948664903641\n",
      "step: 1370, task: Structured/Beer, loss: 0.0009037088602781296\n",
      "step: 1380, task: Structured/Beer, loss: 0.001347036100924015\n",
      "step: 1390, task: Structured/Beer, loss: 0.0008971597999334335\n",
      "step: 1400, task: Structured/Beer, loss: 0.0006478019058704376\n",
      "step: 1410, task: Structured/Beer, loss: 0.004765963181853294\n",
      "step: 1420, task: Structured/Beer, loss: 0.0008873008191585541\n",
      "step: 1430, task: Structured/Beer, loss: 0.05334489792585373\n",
      "step: 1440, task: Structured/Beer, loss: 0.0010213004425168037\n",
      "step: 1450, task: Structured/Beer, loss: 0.0016092825680971146\n",
      "step: 1460, task: Structured/Beer, loss: 0.00187633465975523\n",
      "step: 1470, task: Structured/Beer, loss: 0.0009560538455843925\n",
      "step: 1480, task: Structured/Beer, loss: 0.0017304783686995506\n",
      "step: 1490, task: Structured/Beer, loss: 0.03926330804824829\n",
      "step: 1500, task: Structured/Beer, loss: 0.0017145425081253052\n",
      "step: 1510, task: Structured/Beer, loss: 0.0013525523245334625\n",
      "step: 1520, task: Structured/Beer, loss: 0.0010383501648902893\n",
      "step: 1530, task: Structured/Beer, loss: 0.0013181790709495544\n",
      "step: 1540, task: Structured/Beer, loss: 0.001422664150595665\n",
      "step: 1550, task: Structured/Beer, loss: 0.08322016149759293\n",
      "step: 1560, task: Structured/Beer, loss: 0.007223877590149641\n",
      "step: 1570, task: Structured/Beer, loss: 0.030715439468622208\n",
      "step: 1580, task: Structured/Beer, loss: 0.05723164603114128\n",
      "step: 1590, task: Structured/Beer, loss: 0.05361687391996384\n",
      "step: 1600, task: Structured/Beer, loss: 0.0037089933175593615\n",
      "step: 1610, task: Structured/Beer, loss: 0.0012164600193500519\n",
      "step: 1620, task: Structured/Beer, loss: 0.0011199237778782845\n",
      "step: 1630, task: Structured/Beer, loss: 0.0008068960160017014\n",
      "step: 1640, task: Structured/Beer, loss: 0.035345591604709625\n",
      "step: 1650, task: Structured/Beer, loss: 0.006385732442140579\n",
      "step: 1660, task: Structured/Beer, loss: 0.0011259401217103004\n",
      "step: 1670, task: Structured/Beer, loss: 0.0008471459150314331\n",
      "step: 1680, task: Structured/Beer, loss: 0.001077747903764248\n",
      "step: 1690, task: Structured/Beer, loss: 0.000828128308057785\n",
      "step: 1700, task: Structured/Beer, loss: 0.0009707426652312279\n",
      "step: 1710, task: Structured/Beer, loss: 0.0009736884385347366\n",
      "step: 1720, task: Structured/Beer, loss: 0.0007816683501005173\n",
      "step: 1730, task: Structured/Beer, loss: 0.0008188998326659203\n",
      "step: 1740, task: Structured/Beer, loss: 0.0010592928156256676\n",
      "step: 1750, task: Structured/Beer, loss: 0.0014476869255304337\n",
      "step: 1760, task: Structured/Beer, loss: 0.0006757359951734543\n",
      "step: 1770, task: Structured/Beer, loss: 0.0010107392445206642\n",
      "step: 1780, task: Structured/Beer, loss: 0.001770906150341034\n",
      "step: 1790, task: Structured/Beer, loss: 0.006440709810703993\n",
      "step: 1800, task: Structured/Beer, loss: 0.001987357158213854\n",
      "step: 1810, task: Structured/Beer, loss: 0.001571904867887497\n",
      "step: 1820, task: Structured/Beer, loss: 0.0013819057494401932\n",
      "step: 1830, task: Structured/Beer, loss: 0.05331018567085266\n",
      "step: 1840, task: Structured/Beer, loss: 0.001180930994451046\n",
      "step: 1850, task: Structured/Beer, loss: 0.0008381325751543045\n",
      "step: 1860, task: Structured/Beer, loss: 0.003322239499539137\n",
      "step: 1870, task: Structured/Beer, loss: 0.020015988498926163\n",
      "step: 1880, task: Structured/Beer, loss: 0.0008566034957766533\n",
      "step: 1890, task: Structured/Beer, loss: 0.0018945583142340183\n",
      "step: 1900, task: Structured/Beer, loss: 0.002321189269423485\n",
      "step: 1910, task: Structured/Beer, loss: 0.0013476366875693202\n",
      "step: 1920, task: Structured/Beer, loss: 0.0008207280188798904\n",
      "step: 1930, task: Structured/Beer, loss: 0.002899186685681343\n",
      "step: 1940, task: Structured/Beer, loss: 0.0012697548372671008\n",
      "step: 1950, task: Structured/Beer, loss: 0.0009994041174650192\n",
      "step: 1960, task: Structured/Beer, loss: 0.024076851084828377\n",
      "step: 1970, task: Structured/Beer, loss: 0.002459918148815632\n",
      "step: 1980, task: Structured/Beer, loss: 0.006179219577461481\n",
      "step: 1990, task: Structured/Beer, loss: 0.041168659925460815\n",
      "step: 2000, task: Structured/Beer, loss: 0.0019931485876441\n",
      "step: 2010, task: Structured/Beer, loss: 0.03657747060060501\n",
      "step: 2020, task: Structured/Beer, loss: 0.0008568232879042625\n",
      "step: 2030, task: Structured/Beer, loss: 0.007773116230964661\n",
      "step: 2040, task: Structured/Beer, loss: 0.04954557493329048\n",
      "step: 2050, task: Structured/Beer, loss: 0.0012290775775909424\n",
      "step: 2060, task: Structured/Beer, loss: 0.0012588519603013992\n",
      "step: 2070, task: Structured/Beer, loss: 0.006159691140055656\n",
      "step: 2080, task: Structured/Beer, loss: 0.0034870775416493416\n",
      "step: 2090, task: Structured/Beer, loss: 0.0018543610349297523\n",
      "step: 2100, task: Structured/Beer, loss: 0.012850896455347538\n",
      "step: 2110, task: Structured/Beer, loss: 0.009130266495049\n",
      "step: 2120, task: Structured/Beer, loss: 0.06382209062576294\n",
      "step: 2130, task: Structured/Beer, loss: 0.0017393426969647408\n",
      "step: 2140, task: Structured/Beer, loss: 0.08193497359752655\n",
      "step: 2150, task: Structured/Beer, loss: 0.0015203040093183517\n",
      "step: 2160, task: Structured/Beer, loss: 0.003210783004760742\n",
      "step: 2170, task: Structured/Beer, loss: 0.0010011810809373856\n",
      "step: 2180, task: Structured/Beer, loss: 0.0016987129347398877\n",
      "step: 2190, task: Structured/Beer, loss: 0.004305942915380001\n",
      "step: 2200, task: Structured/Beer, loss: 0.0012749284505844116\n",
      "step: 2210, task: Structured/Beer, loss: 0.003434194251894951\n",
      "step: 2220, task: Structured/Beer, loss: 0.0012231413275003433\n",
      "step: 2230, task: Structured/Beer, loss: 0.0721045434474945\n",
      "step: 2240, task: Structured/Beer, loss: 0.0008617248386144638\n",
      "step: 2250, task: Structured/Beer, loss: 0.05854257196187973\n",
      "step: 2260, task: Structured/Beer, loss: 0.03472069278359413\n",
      "step: 2270, task: Structured/Beer, loss: 0.0016474779695272446\n",
      "step: 2280, task: Structured/Beer, loss: 0.011497443541884422\n",
      "step: 2290, task: Structured/Beer, loss: 0.0015371291665360332\n",
      "step: 2300, task: Structured/Beer, loss: 0.0013509942218661308\n",
      "step: 2310, task: Structured/Beer, loss: 0.004253503866493702\n",
      "step: 2320, task: Structured/Beer, loss: 0.003660485614091158\n",
      "step: 2330, task: Structured/Beer, loss: 0.05013561248779297\n",
      "step: 2340, task: Structured/Beer, loss: 0.005130370147526264\n",
      "step: 2350, task: Structured/Beer, loss: 0.05715891718864441\n",
      "step: 2360, task: Structured/Beer, loss: 0.03315580263733864\n",
      "step: 2370, task: Structured/Beer, loss: 0.0013157278299331665\n",
      "step: 2380, task: Structured/Beer, loss: 0.00295519782230258\n",
      "step: 2390, task: Structured/Beer, loss: 0.001675248146057129\n",
      "step: 2400, task: Structured/Beer, loss: 0.005828802939504385\n",
      "step: 2410, task: Structured/Beer, loss: 0.0013108998537063599\n",
      "step: 2420, task: Structured/Beer, loss: 0.038747433573007584\n",
      "step: 2430, task: Structured/Beer, loss: 0.024664754047989845\n",
      "step: 2440, task: Structured/Beer, loss: 0.0014065355062484741\n",
      "step: 2450, task: Structured/Beer, loss: 0.003230977337807417\n",
      "step: 2460, task: Structured/Beer, loss: 0.002276996150612831\n",
      "step: 2470, task: Structured/Beer, loss: 0.0011664899066090584\n",
      "step: 2480, task: Structured/Beer, loss: 0.0019018203020095825\n",
      "step: 2490, task: Structured/Beer, loss: 0.018430307507514954\n",
      "step: 2500, task: Structured/Beer, loss: 0.0011416245251893997\n",
      "step: 2510, task: Structured/Beer, loss: 0.0009899362921714783\n",
      "step: 2520, task: Structured/Beer, loss: 0.006182472687214613\n",
      "step: 2530, task: Structured/Beer, loss: 0.04977650195360184\n",
      "step: 2540, task: Structured/Beer, loss: 0.0010992791503667831\n",
      "step: 2550, task: Structured/Beer, loss: 0.0013496875762939453\n",
      "step: 2560, task: Structured/Beer, loss: 0.0008257291628979146\n",
      "step: 2570, task: Structured/Beer, loss: 0.0843200609087944\n",
      "step: 2580, task: Structured/Beer, loss: 0.0018548127263784409\n",
      "step: 2590, task: Structured/Beer, loss: 0.0012855706736445427\n",
      "step: 2600, task: Structured/Beer, loss: 0.001954064704477787\n",
      "step: 2610, task: Structured/Beer, loss: 0.0013228198513388634\n",
      "step: 2620, task: Structured/Beer, loss: 0.0010303277522325516\n",
      "step: 2630, task: Structured/Beer, loss: 0.0008221752941608429\n",
      "step: 2640, task: Structured/Beer, loss: 0.00135823804885149\n",
      "step: 2650, task: Structured/Beer, loss: 0.0009614778682589531\n",
      "step: 2660, task: Structured/Beer, loss: 0.00121215358376503\n",
      "step: 2670, task: Structured/Beer, loss: 0.0018863389268517494\n",
      "step: 2680, task: Structured/Beer, loss: 0.0008115563541650772\n",
      "step: 2690, task: Structured/Beer, loss: 0.0009939856827259064\n",
      "step: 2700, task: Structured/Beer, loss: 0.01069479901343584\n",
      "step: 2710, task: Structured/Beer, loss: 0.0011991914361715317\n",
      "step: 2720, task: Structured/Beer, loss: 0.001548004220239818\n",
      "step: 2730, task: Structured/Beer, loss: 0.0008065328001976013\n",
      "step: 2740, task: Structured/Beer, loss: 0.049177106469869614\n",
      "step: 2750, task: Structured/Beer, loss: 0.0015818310203030705\n",
      "step: 2760, task: Structured/Beer, loss: 0.03753771632909775\n",
      "step: 2770, task: Structured/Beer, loss: 0.0011782627552747726\n",
      "step: 2780, task: Structured/Beer, loss: 0.0011613601818680763\n",
      "step: 2790, task: Structured/Beer, loss: 0.001133686862885952\n",
      "step: 2800, task: Structured/Beer, loss: 0.002346327994018793\n",
      "step: 2810, task: Structured/Beer, loss: 0.0023194970563054085\n",
      "step: 2820, task: Structured/Beer, loss: 0.0011611543595790863\n",
      "step: 2830, task: Structured/Beer, loss: 0.0010389741510152817\n",
      "step: 2840, task: Structured/Beer, loss: 0.0010482724756002426\n",
      "step: 2850, task: Structured/Beer, loss: 0.022493287920951843\n",
      "step: 2860, task: Structured/Beer, loss: 0.0015340903773903847\n",
      "step: 2870, task: Structured/Beer, loss: 0.005612807814031839\n",
      "step: 2880, task: Structured/Beer, loss: 0.004997157026082277\n",
      "step: 2890, task: Structured/Beer, loss: 0.010311982594430447\n",
      "step: 2900, task: Structured/Beer, loss: 0.0033070454373955727\n",
      "step: 2910, task: Structured/Beer, loss: 0.0044121816754341125\n",
      "step: 2920, task: Structured/Beer, loss: 0.003158214734867215\n",
      "step: 2930, task: Structured/Beer, loss: 0.0025938376784324646\n",
      "step: 2940, task: Structured/Beer, loss: 0.0034866835922002792\n",
      "step: 2950, task: Structured/Beer, loss: 0.0011410843580961227\n",
      "step: 2960, task: Structured/Beer, loss: 0.0014093387871980667\n",
      "step: 2970, task: Structured/Beer, loss: 0.116502545773983\n",
      "step: 2980, task: Structured/Beer, loss: 0.0032774347346276045\n",
      "step: 2990, task: Structured/Beer, loss: 0.007764661684632301\n",
      "step: 3000, task: Structured/Beer, loss: 0.010147803463041782\n",
      "step: 3010, task: Structured/Beer, loss: 0.002196566667407751\n",
      "step: 3020, task: Structured/Beer, loss: 0.020082661882042885\n",
      "step: 3030, task: Structured/Beer, loss: 0.001226949505507946\n",
      "step: 3040, task: Structured/Beer, loss: 0.0026904363185167313\n",
      "step: 3050, task: Structured/Beer, loss: 0.000940980389714241\n",
      "step: 3060, task: Structured/Beer, loss: 0.000937681645154953\n",
      "=========eval at epoch=1=========\n",
      "Validation:\n",
      "=============Structured/Beer==================\n",
      "accuracy=0.996\n",
      "precision=0.060\n",
      "recall=0.062\n",
      "f1=0.061\n",
      "======================================\n",
      "Test:\n",
      "=============Structured/Beer==================\n",
      "accuracy=0.996\n",
      "precision=0.059\n",
      "recall=0.073\n",
      "f1=0.066\n",
      "======================================\n",
      "=====sanity check======\n",
      "words: COL movie VAL matthew mcconaughey anne hathaway mackenzie foy color pg13 christopher nolan english usa  2014 [SEP] COL movie VAL One of Angelina's best performances and one of the best movies I've ever seen and the music was so movie but what i actually liked the most in this film was Angelina's performance she made me cry . i give it a 10 * and if you liked this movie you should watch GIA . Well when i finished the movie and got back home i gave my mom a big hug . Anyway the directing was a masterpiece and thank to Angelina the movie was brilliant and absolutely strangely moving i would watch it over and over .And Jolie deserved the Oscar for this role that was really a gorgeous and attractive way to see how much a mother loves her sun i wanted to see the movie the minute i saw the trailer\n",
      "x: [  101  8902  3185 11748  5487 23680  7856  8953  3240  4776  6045 14238\n",
      "  4710 11407  1042  6977  3609 18720 17134  5696 13401  2394  3915  2297\n",
      "   102  8902  3185 11748  2028  1997 23847  1005  1055  2190  4616  1998\n",
      "  2028  1997  1996  2190  5691  1045  1005  2310  2412  2464  1998  1996\n",
      "  2189  2001  2061  3185  2021  2054  1045  2941  4669  1996  2087  1999\n",
      "  2023  2143  2001 23847  1005  1055  2836  2016  2081  2033  5390  1012\n",
      "  1045  2507  2009  1037  2184  1008  1998  2065  2017  4669  2023  3185\n",
      "  2017  2323  3422 27699  1012  2092  2043  1045  2736  1996  3185  1998\n",
      "  2288  2067  2188  1045  2435  2026  3566  1037  2502  8549  1012  4312\n",
      "  1996  9855  2001  1037 17743  1998  4067  2000 23847  1996  3185  2001\n",
      "  8235  1998  7078 13939  3048  1045  2052   102]\n",
      "tokens: ['[CLS]', 'col', 'movie', 'val', 'matthew', 'mcc', '##ona', '##ugh', '##ey', 'anne', 'hat', '##haw', '##ay', 'mackenzie', 'f', '##oy', 'color', 'pg', '##13', 'christopher', 'nolan', 'english', 'usa', '2014', '[SEP]', 'col', 'movie', 'val', 'one', 'of', 'angelina', \"'\", 's', 'best', 'performances', 'and', 'one', 'of', 'the', 'best', 'movies', 'i', \"'\", 've', 'ever', 'seen', 'and', 'the', 'music', 'was', 'so', 'movie', 'but', 'what', 'i', 'actually', 'liked', 'the', 'most', 'in', 'this', 'film', 'was', 'angelina', \"'\", 's', 'performance', 'she', 'made', 'me', 'cry', '.', 'i', 'give', 'it', 'a', '10', '*', 'and', 'if', 'you', 'liked', 'this', 'movie', 'you', 'should', 'watch', 'gia', '.', 'well', 'when', 'i', 'finished', 'the', 'movie', 'and', 'got', 'back', 'home', 'i', 'gave', 'my', 'mom', 'a', 'big', 'hug', '.', 'anyway', 'the', 'directing', 'was', 'a', 'masterpiece', 'and', 'thank', 'to', 'angelina', 'the', 'movie', 'was', 'brilliant', 'and', 'absolutely', 'strangely', 'moving', 'i', 'would', '[SEP]']\n",
      "is_heads: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "y: 0\n",
      "tags: 0\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "seqlen: 128\n",
      "task_name: Structured/Beer\n",
      "=======================\n",
      "step: 0, task: Structured/Beer, loss: 0.0008475948125123978\n",
      "step: 10, task: Structured/Beer, loss: 0.0009985435754060745\n",
      "step: 20, task: Structured/Beer, loss: 0.0020519073586910963\n",
      "step: 30, task: Structured/Beer, loss: 0.05334062874317169\n",
      "step: 40, task: Structured/Beer, loss: 0.0028997533954679966\n",
      "step: 50, task: Structured/Beer, loss: 0.0016738134436309338\n",
      "step: 60, task: Structured/Beer, loss: 0.00935947336256504\n",
      "step: 70, task: Structured/Beer, loss: 0.0011680275201797485\n",
      "step: 80, task: Structured/Beer, loss: 0.001218114048242569\n",
      "step: 90, task: Structured/Beer, loss: 0.0015490557998418808\n",
      "step: 100, task: Structured/Beer, loss: 0.0017108004540205002\n",
      "step: 110, task: Structured/Beer, loss: 0.0008456800132989883\n",
      "step: 120, task: Structured/Beer, loss: 0.04892672598361969\n",
      "step: 130, task: Structured/Beer, loss: 0.006964273750782013\n",
      "step: 140, task: Structured/Beer, loss: 0.0019207252189517021\n",
      "step: 150, task: Structured/Beer, loss: 0.0009180335327982903\n",
      "step: 160, task: Structured/Beer, loss: 0.0008835457265377045\n",
      "step: 170, task: Structured/Beer, loss: 0.00560860987752676\n",
      "step: 180, task: Structured/Beer, loss: 0.001204061321914196\n",
      "step: 190, task: Structured/Beer, loss: 0.03641654551029205\n",
      "step: 200, task: Structured/Beer, loss: 0.050072796642780304\n",
      "step: 210, task: Structured/Beer, loss: 0.005361001938581467\n",
      "step: 220, task: Structured/Beer, loss: 0.07304069399833679\n",
      "step: 230, task: Structured/Beer, loss: 0.0009779706597328186\n",
      "step: 240, task: Structured/Beer, loss: 0.0053391526453197\n",
      "step: 250, task: Structured/Beer, loss: 0.00186142697930336\n",
      "step: 260, task: Structured/Beer, loss: 0.0011764885857701302\n",
      "step: 270, task: Structured/Beer, loss: 0.00080874003469944\n",
      "step: 280, task: Structured/Beer, loss: 0.0031036166474223137\n",
      "step: 290, task: Structured/Beer, loss: 0.003703539725393057\n",
      "step: 300, task: Structured/Beer, loss: 0.02658507414162159\n",
      "step: 310, task: Structured/Beer, loss: 0.00110664963722229\n",
      "step: 320, task: Structured/Beer, loss: 0.006773404777050018\n",
      "step: 330, task: Structured/Beer, loss: 0.002931438386440277\n",
      "step: 340, task: Structured/Beer, loss: 0.0009612385183572769\n",
      "step: 350, task: Structured/Beer, loss: 0.0016658985987305641\n",
      "step: 360, task: Structured/Beer, loss: 0.0009900517761707306\n",
      "step: 370, task: Structured/Beer, loss: 0.006787241902202368\n",
      "step: 380, task: Structured/Beer, loss: 0.0013370653614401817\n",
      "step: 390, task: Structured/Beer, loss: 0.001066151075065136\n",
      "step: 400, task: Structured/Beer, loss: 0.0018500742735341191\n",
      "step: 410, task: Structured/Beer, loss: 0.0035870512947440147\n",
      "step: 420, task: Structured/Beer, loss: 0.018588125705718994\n",
      "step: 430, task: Structured/Beer, loss: 0.0011354275047779083\n",
      "step: 440, task: Structured/Beer, loss: 0.0009747948497533798\n",
      "step: 450, task: Structured/Beer, loss: 0.0010863188654184341\n",
      "step: 460, task: Structured/Beer, loss: 0.0009402036666870117\n",
      "step: 470, task: Structured/Beer, loss: 0.0009044501930475235\n",
      "step: 480, task: Structured/Beer, loss: 0.0013004867359995842\n",
      "step: 490, task: Structured/Beer, loss: 0.0008435267955064774\n",
      "step: 500, task: Structured/Beer, loss: 0.0014087455347180367\n",
      "step: 510, task: Structured/Beer, loss: 0.020939603447914124\n",
      "step: 520, task: Structured/Beer, loss: 0.0032504608388990164\n",
      "step: 530, task: Structured/Beer, loss: 0.0015300055965781212\n",
      "step: 540, task: Structured/Beer, loss: 0.0016793236136436462\n",
      "step: 550, task: Structured/Beer, loss: 0.0009930124506354332\n",
      "step: 560, task: Structured/Beer, loss: 0.0012607257813215256\n",
      "step: 570, task: Structured/Beer, loss: 0.05879078060388565\n",
      "step: 580, task: Structured/Beer, loss: 0.022120371460914612\n",
      "step: 590, task: Structured/Beer, loss: 0.0019273613579571247\n",
      "step: 600, task: Structured/Beer, loss: 0.005413890350610018\n",
      "step: 610, task: Structured/Beer, loss: 0.0014207186177372932\n",
      "step: 620, task: Structured/Beer, loss: 0.005772022530436516\n",
      "step: 630, task: Structured/Beer, loss: 0.0010048449039459229\n",
      "step: 640, task: Structured/Beer, loss: 0.015347844921052456\n",
      "step: 650, task: Structured/Beer, loss: 0.0013391581596806645\n",
      "step: 660, task: Structured/Beer, loss: 0.0010667052119970322\n",
      "step: 670, task: Structured/Beer, loss: 0.0011380622163414955\n",
      "step: 680, task: Structured/Beer, loss: 0.019278796389698982\n",
      "step: 690, task: Structured/Beer, loss: 0.03308912366628647\n",
      "step: 700, task: Structured/Beer, loss: 0.0008927565068006516\n",
      "step: 710, task: Structured/Beer, loss: 0.05226008966565132\n",
      "step: 720, task: Structured/Beer, loss: 0.0018994268029928207\n",
      "step: 730, task: Structured/Beer, loss: 0.0008844081312417984\n",
      "step: 740, task: Structured/Beer, loss: 0.01705673709511757\n",
      "step: 750, task: Structured/Beer, loss: 0.0010463865473866463\n",
      "step: 760, task: Structured/Beer, loss: 0.0008161105215549469\n",
      "step: 770, task: Structured/Beer, loss: 0.0020656236447393894\n",
      "step: 780, task: Structured/Beer, loss: 0.003581106197088957\n",
      "step: 790, task: Structured/Beer, loss: 0.0012137657031416893\n",
      "step: 800, task: Structured/Beer, loss: 0.0021373098716139793\n",
      "step: 810, task: Structured/Beer, loss: 0.0022698063403367996\n",
      "step: 820, task: Structured/Beer, loss: 0.0009803399443626404\n",
      "step: 830, task: Structured/Beer, loss: 0.0014884062111377716\n",
      "step: 840, task: Structured/Beer, loss: 0.0009680110961198807\n",
      "step: 850, task: Structured/Beer, loss: 0.00704667903482914\n",
      "step: 860, task: Structured/Beer, loss: 0.0017138305120170116\n",
      "step: 870, task: Structured/Beer, loss: 0.002735670655965805\n",
      "step: 880, task: Structured/Beer, loss: 0.0012414194643497467\n",
      "step: 890, task: Structured/Beer, loss: 0.0018123704940080643\n",
      "step: 900, task: Structured/Beer, loss: 0.060869790613651276\n",
      "step: 910, task: Structured/Beer, loss: 0.0028064108919352293\n",
      "step: 920, task: Structured/Beer, loss: 0.0010090293362736702\n",
      "step: 930, task: Structured/Beer, loss: 0.007071570958942175\n",
      "step: 940, task: Structured/Beer, loss: 0.002598647028207779\n",
      "step: 950, task: Structured/Beer, loss: 0.0009078523144125938\n",
      "step: 960, task: Structured/Beer, loss: 0.0018199533224105835\n",
      "step: 970, task: Structured/Beer, loss: 0.010602951981127262\n",
      "step: 980, task: Structured/Beer, loss: 0.011396422982215881\n",
      "step: 990, task: Structured/Beer, loss: 0.00076424510916695\n",
      "step: 1000, task: Structured/Beer, loss: 0.0010939165949821472\n",
      "step: 1010, task: Structured/Beer, loss: 0.013587689027190208\n",
      "step: 1020, task: Structured/Beer, loss: 0.0013477038592100143\n",
      "step: 1030, task: Structured/Beer, loss: 0.0011237608268857002\n",
      "step: 1040, task: Structured/Beer, loss: 0.030129795894026756\n",
      "step: 1050, task: Structured/Beer, loss: 0.0009371694177389145\n",
      "step: 1060, task: Structured/Beer, loss: 0.0011582152219489217\n",
      "step: 1070, task: Structured/Beer, loss: 0.0008465386927127838\n",
      "step: 1080, task: Structured/Beer, loss: 0.0016375947743654251\n",
      "step: 1090, task: Structured/Beer, loss: 0.016873255372047424\n",
      "step: 1100, task: Structured/Beer, loss: 0.000922996609006077\n",
      "step: 1110, task: Structured/Beer, loss: 0.002139532472938299\n",
      "step: 1120, task: Structured/Beer, loss: 0.0012617586180567741\n",
      "step: 1130, task: Structured/Beer, loss: 0.0009679645299911499\n",
      "step: 1140, task: Structured/Beer, loss: 0.0011924142017960548\n",
      "step: 1150, task: Structured/Beer, loss: 0.0009261034429073334\n",
      "step: 1160, task: Structured/Beer, loss: 0.0010892899008467793\n",
      "step: 1170, task: Structured/Beer, loss: 0.0023614224046468735\n",
      "step: 1180, task: Structured/Beer, loss: 0.002735973335802555\n",
      "step: 1190, task: Structured/Beer, loss: 0.0009825285524129868\n",
      "step: 1200, task: Structured/Beer, loss: 0.0017846515402197838\n",
      "step: 1210, task: Structured/Beer, loss: 0.0016013309359550476\n",
      "step: 1220, task: Structured/Beer, loss: 0.002274896949529648\n",
      "step: 1230, task: Structured/Beer, loss: 0.05212962627410889\n",
      "step: 1240, task: Structured/Beer, loss: 0.0028802836313843727\n",
      "step: 1250, task: Structured/Beer, loss: 0.0008936095982789993\n",
      "step: 1260, task: Structured/Beer, loss: 0.0011864351108670235\n",
      "step: 1270, task: Structured/Beer, loss: 0.05499468371272087\n",
      "step: 1280, task: Structured/Beer, loss: 0.0010777506977319717\n",
      "step: 1290, task: Structured/Beer, loss: 0.0018751187017187476\n",
      "step: 1300, task: Structured/Beer, loss: 0.0010440787300467491\n",
      "step: 1310, task: Structured/Beer, loss: 0.0032372847199440002\n",
      "step: 1320, task: Structured/Beer, loss: 0.007002097554504871\n",
      "step: 1330, task: Structured/Beer, loss: 0.0008588014170527458\n",
      "step: 1340, task: Structured/Beer, loss: 0.0548565536737442\n",
      "step: 1350, task: Structured/Beer, loss: 0.0014333920553326607\n",
      "step: 1360, task: Structured/Beer, loss: 0.0018718111095950007\n",
      "step: 1370, task: Structured/Beer, loss: 0.005535947158932686\n",
      "step: 1380, task: Structured/Beer, loss: 0.0009917337447404861\n",
      "step: 1390, task: Structured/Beer, loss: 0.0017989510670304298\n",
      "step: 1400, task: Structured/Beer, loss: 0.020847061648964882\n",
      "step: 1410, task: Structured/Beer, loss: 0.0009590182453393936\n",
      "step: 1420, task: Structured/Beer, loss: 0.0012836037203669548\n",
      "step: 1430, task: Structured/Beer, loss: 0.0012602731585502625\n",
      "step: 1440, task: Structured/Beer, loss: 0.0018523717299103737\n",
      "step: 1450, task: Structured/Beer, loss: 0.002553451806306839\n",
      "step: 1460, task: Structured/Beer, loss: 0.001338317058980465\n",
      "step: 1470, task: Structured/Beer, loss: 0.0021722246892750263\n",
      "step: 1480, task: Structured/Beer, loss: 0.0008774455636739731\n",
      "step: 1490, task: Structured/Beer, loss: 0.0013104360550642014\n",
      "step: 1500, task: Structured/Beer, loss: 0.0008855937048792839\n",
      "step: 1510, task: Structured/Beer, loss: 0.0010517045157030225\n",
      "step: 1520, task: Structured/Beer, loss: 0.04090810567140579\n",
      "step: 1530, task: Structured/Beer, loss: 0.0034119999036192894\n",
      "step: 1540, task: Structured/Beer, loss: 0.0036800443194806576\n",
      "step: 1550, task: Structured/Beer, loss: 0.00087742879986763\n",
      "step: 1560, task: Structured/Beer, loss: 0.008593347854912281\n",
      "step: 1570, task: Structured/Beer, loss: 0.0008689723908901215\n",
      "step: 1580, task: Structured/Beer, loss: 0.0070693884044885635\n",
      "step: 1590, task: Structured/Beer, loss: 0.0020270459353923798\n",
      "step: 1600, task: Structured/Beer, loss: 0.001025657169520855\n",
      "step: 1610, task: Structured/Beer, loss: 0.010755506344139576\n",
      "step: 1620, task: Structured/Beer, loss: 0.0030607571825385094\n",
      "step: 1630, task: Structured/Beer, loss: 0.0013533738674595952\n",
      "step: 1640, task: Structured/Beer, loss: 0.0009517297148704529\n",
      "step: 1650, task: Structured/Beer, loss: 0.05196162313222885\n",
      "step: 1660, task: Structured/Beer, loss: 0.0018786416621878743\n",
      "step: 1670, task: Structured/Beer, loss: 0.0009413538500666618\n",
      "step: 1680, task: Structured/Beer, loss: 0.0012086210772395134\n",
      "step: 1690, task: Structured/Beer, loss: 0.0034228935837745667\n",
      "step: 1700, task: Structured/Beer, loss: 0.02939893677830696\n",
      "step: 1710, task: Structured/Beer, loss: 0.0010816222056746483\n",
      "step: 1720, task: Structured/Beer, loss: 0.0010265577584505081\n",
      "step: 1730, task: Structured/Beer, loss: 0.030880117788910866\n",
      "step: 1740, task: Structured/Beer, loss: 0.0014890023740008473\n",
      "step: 1750, task: Structured/Beer, loss: 0.006922617554664612\n",
      "step: 1760, task: Structured/Beer, loss: 0.0012626443058252335\n",
      "step: 1770, task: Structured/Beer, loss: 0.0010614637285470963\n",
      "step: 1780, task: Structured/Beer, loss: 0.002395596355199814\n",
      "step: 1790, task: Structured/Beer, loss: 0.0013774903491139412\n",
      "step: 1800, task: Structured/Beer, loss: 0.002118334174156189\n",
      "step: 1810, task: Structured/Beer, loss: 0.0009616967290639877\n",
      "step: 1820, task: Structured/Beer, loss: 0.0010442091152071953\n",
      "step: 1830, task: Structured/Beer, loss: 0.05010220408439636\n",
      "step: 1840, task: Structured/Beer, loss: 0.0008650049567222595\n",
      "step: 1850, task: Structured/Beer, loss: 0.0026184399612247944\n",
      "step: 1860, task: Structured/Beer, loss: 0.001570054329931736\n",
      "step: 1870, task: Structured/Beer, loss: 0.0017983871512115002\n",
      "step: 1880, task: Structured/Beer, loss: 0.0010227598249912262\n",
      "step: 1890, task: Structured/Beer, loss: 0.04335739463567734\n",
      "step: 1900, task: Structured/Beer, loss: 0.016462847590446472\n",
      "step: 1910, task: Structured/Beer, loss: 0.0035082511603832245\n",
      "step: 1920, task: Structured/Beer, loss: 0.0008038171217776835\n",
      "step: 1930, task: Structured/Beer, loss: 0.0010902797803282738\n",
      "step: 1940, task: Structured/Beer, loss: 0.0008529182523488998\n",
      "step: 1950, task: Structured/Beer, loss: 0.0010430794209241867\n",
      "step: 1960, task: Structured/Beer, loss: 0.0009702770039439201\n",
      "step: 1970, task: Structured/Beer, loss: 0.002358937170356512\n",
      "step: 1980, task: Structured/Beer, loss: 0.000905059278011322\n",
      "step: 1990, task: Structured/Beer, loss: 0.060143545269966125\n",
      "step: 2000, task: Structured/Beer, loss: 0.012461693026125431\n",
      "step: 2010, task: Structured/Beer, loss: 0.0009712083265185356\n",
      "step: 2020, task: Structured/Beer, loss: 0.0008976776152849197\n",
      "step: 2030, task: Structured/Beer, loss: 0.059105705469846725\n",
      "step: 2040, task: Structured/Beer, loss: 0.001244615763425827\n",
      "step: 2050, task: Structured/Beer, loss: 0.0009255623444914818\n",
      "step: 2060, task: Structured/Beer, loss: 0.0011519156396389008\n",
      "step: 2070, task: Structured/Beer, loss: 0.001513487659394741\n",
      "step: 2080, task: Structured/Beer, loss: 0.0011058170348405838\n",
      "step: 2090, task: Structured/Beer, loss: 0.0027787084691226482\n",
      "step: 2100, task: Structured/Beer, loss: 0.001040714792907238\n",
      "step: 2110, task: Structured/Beer, loss: 0.012195024639368057\n",
      "step: 2120, task: Structured/Beer, loss: 0.0021743010729551315\n",
      "step: 2130, task: Structured/Beer, loss: 0.004385091830044985\n",
      "step: 2140, task: Structured/Beer, loss: 0.0011707926169037819\n",
      "step: 2150, task: Structured/Beer, loss: 0.0015452522784471512\n",
      "step: 2160, task: Structured/Beer, loss: 0.0013454100117087364\n",
      "step: 2170, task: Structured/Beer, loss: 0.0016353895189240575\n",
      "step: 2180, task: Structured/Beer, loss: 0.0010104943066835403\n",
      "step: 2190, task: Structured/Beer, loss: 0.0016666492447257042\n",
      "step: 2200, task: Structured/Beer, loss: 0.048508092761039734\n",
      "step: 2210, task: Structured/Beer, loss: 0.0024342909455299377\n",
      "step: 2220, task: Structured/Beer, loss: 0.0011369334533810616\n",
      "step: 2230, task: Structured/Beer, loss: 0.006575567647814751\n",
      "step: 2240, task: Structured/Beer, loss: 0.0025097071193158627\n",
      "step: 2250, task: Structured/Beer, loss: 0.0024500107392668724\n",
      "step: 2260, task: Structured/Beer, loss: 0.0010008849203586578\n",
      "step: 2270, task: Structured/Beer, loss: 0.002543411683291197\n",
      "step: 2280, task: Structured/Beer, loss: 0.0015467219054698944\n",
      "step: 2290, task: Structured/Beer, loss: 0.0008366256952285767\n",
      "step: 2300, task: Structured/Beer, loss: 0.0015219906345009804\n",
      "step: 2310, task: Structured/Beer, loss: 0.000893888995051384\n",
      "step: 2320, task: Structured/Beer, loss: 0.007130430079996586\n",
      "step: 2330, task: Structured/Beer, loss: 0.060638368129730225\n",
      "step: 2340, task: Structured/Beer, loss: 0.0010148324072360992\n",
      "step: 2350, task: Structured/Beer, loss: 0.007572083733975887\n",
      "step: 2360, task: Structured/Beer, loss: 0.0036962172016501427\n",
      "step: 2370, task: Structured/Beer, loss: 0.0008599795401096344\n",
      "step: 2380, task: Structured/Beer, loss: 0.0012885378673672676\n",
      "step: 2390, task: Structured/Beer, loss: 0.0009899092838168144\n",
      "step: 2400, task: Structured/Beer, loss: 0.0026349537074565887\n",
      "step: 2410, task: Structured/Beer, loss: 0.0014504669234156609\n",
      "step: 2420, task: Structured/Beer, loss: 0.0016501471400260925\n",
      "step: 2430, task: Structured/Beer, loss: 0.016846613958477974\n",
      "step: 2440, task: Structured/Beer, loss: 0.0020677936263382435\n",
      "step: 2450, task: Structured/Beer, loss: 0.002111160196363926\n",
      "step: 2460, task: Structured/Beer, loss: 0.0018979785963892937\n",
      "step: 2470, task: Structured/Beer, loss: 0.002243144903331995\n",
      "step: 2480, task: Structured/Beer, loss: 0.001136384904384613\n",
      "step: 2490, task: Structured/Beer, loss: 0.0009023668244481087\n",
      "step: 2500, task: Structured/Beer, loss: 0.0019463887438178062\n",
      "step: 2510, task: Structured/Beer, loss: 0.0016305837780237198\n",
      "step: 2520, task: Structured/Beer, loss: 0.0011672060936689377\n",
      "step: 2530, task: Structured/Beer, loss: 0.05495424568653107\n",
      "step: 2540, task: Structured/Beer, loss: 0.0023560109548270702\n",
      "step: 2550, task: Structured/Beer, loss: 0.008367990143597126\n",
      "step: 2560, task: Structured/Beer, loss: 0.08097881078720093\n",
      "step: 2570, task: Structured/Beer, loss: 0.04807426035404205\n",
      "step: 2580, task: Structured/Beer, loss: 0.0024743201211094856\n",
      "step: 2590, task: Structured/Beer, loss: 0.0010441876947879791\n",
      "step: 2600, task: Structured/Beer, loss: 0.0018303729593753815\n",
      "step: 2610, task: Structured/Beer, loss: 0.0046823881566524506\n",
      "step: 2620, task: Structured/Beer, loss: 0.04594360291957855\n",
      "step: 2630, task: Structured/Beer, loss: 0.03202714025974274\n",
      "step: 2640, task: Structured/Beer, loss: 0.001017722301185131\n",
      "step: 2650, task: Structured/Beer, loss: 0.0015675211325287819\n",
      "step: 2660, task: Structured/Beer, loss: 0.0021061813458800316\n",
      "step: 2670, task: Structured/Beer, loss: 0.0011408636346459389\n",
      "step: 2680, task: Structured/Beer, loss: 0.007544329389929771\n",
      "step: 2690, task: Structured/Beer, loss: 0.001233518123626709\n",
      "step: 2700, task: Structured/Beer, loss: 0.002595525933429599\n",
      "step: 2710, task: Structured/Beer, loss: 0.027510207146406174\n",
      "step: 2720, task: Structured/Beer, loss: 0.00534485001116991\n",
      "step: 2730, task: Structured/Beer, loss: 0.0010916227474808693\n",
      "step: 2740, task: Structured/Beer, loss: 0.015798406675457954\n",
      "step: 2750, task: Structured/Beer, loss: 0.05130493640899658\n",
      "step: 2760, task: Structured/Beer, loss: 0.001086914911866188\n",
      "step: 2770, task: Structured/Beer, loss: 0.0009915437549352646\n",
      "step: 2780, task: Structured/Beer, loss: 0.0010000290349125862\n",
      "step: 2790, task: Structured/Beer, loss: 0.0011599715799093246\n",
      "step: 2800, task: Structured/Beer, loss: 0.0017650640802457929\n",
      "step: 2810, task: Structured/Beer, loss: 0.0008828137069940567\n",
      "step: 2820, task: Structured/Beer, loss: 0.0011752592399716377\n",
      "step: 2830, task: Structured/Beer, loss: 0.0047231209464371204\n",
      "step: 2840, task: Structured/Beer, loss: 0.0012311702594161034\n",
      "step: 2850, task: Structured/Beer, loss: 0.0021264515817165375\n",
      "step: 2860, task: Structured/Beer, loss: 0.006067133508622646\n",
      "step: 2870, task: Structured/Beer, loss: 0.0013976069167256355\n",
      "step: 2880, task: Structured/Beer, loss: 0.001002160832285881\n",
      "step: 2890, task: Structured/Beer, loss: 0.001017184928059578\n",
      "step: 2900, task: Structured/Beer, loss: 0.0009891213849186897\n",
      "step: 2910, task: Structured/Beer, loss: 0.001647474244236946\n",
      "step: 2920, task: Structured/Beer, loss: 0.0028482088819146156\n",
      "step: 2930, task: Structured/Beer, loss: 0.001847475185059011\n",
      "step: 2940, task: Structured/Beer, loss: 0.0011779125779867172\n",
      "step: 2950, task: Structured/Beer, loss: 0.0010109208524227142\n",
      "step: 2960, task: Structured/Beer, loss: 0.0010752566158771515\n",
      "step: 2970, task: Structured/Beer, loss: 0.0035230775829404593\n",
      "step: 2980, task: Structured/Beer, loss: 0.0010733241215348244\n",
      "step: 2990, task: Structured/Beer, loss: 0.05175090581178665\n",
      "step: 3000, task: Structured/Beer, loss: 0.0009343624114990234\n",
      "step: 3010, task: Structured/Beer, loss: 0.004661857150495052\n",
      "step: 3020, task: Structured/Beer, loss: 0.0019679581746459007\n",
      "step: 3030, task: Structured/Beer, loss: 0.0033918709959834814\n",
      "step: 3040, task: Structured/Beer, loss: 0.00242268992587924\n",
      "step: 3050, task: Structured/Beer, loss: 0.0009860489517450333\n",
      "step: 3060, task: Structured/Beer, loss: 0.0015596626326441765\n",
      "=========eval at epoch=2=========\n",
      "Validation:\n",
      "=============Structured/Beer==================\n",
      "accuracy=0.996\n",
      "precision=0.060\n",
      "recall=0.062\n",
      "f1=0.061\n",
      "======================================\n",
      "Test:\n",
      "=============Structured/Beer==================\n",
      "accuracy=0.996\n",
      "precision=0.059\n",
      "recall=0.073\n",
      "f1=0.066\n",
      "======================================\n",
      "32519.49759531021\n"
     ]
    }
   ],
   "source": [
    "# Step 1:\n",
    "# train the wdc model with the save_model flag on\n",
    "# it will produce two files *_dev.pt and *_test.pt which are the \n",
    "# best checkpoints on the dev set and the test set.\n",
    "import time\n",
    "st = time.time()\n",
    "!CUDA_VISIBLE_DEVICES=0 python train_ditto.py \\\n",
    "  --task Structured/Beer \\\n",
    "  --batch_size 128 \\\n",
    "  --max_len 128 \\\n",
    "  --lr 3e-5 \\\n",
    "  --n_epochs 2 \\\n",
    "  --finetuning \\\n",
    "  --lm distilbert \\\n",
    "  --fp16 \\\n",
    "  --save_model \\\n",
    "  --da drop_col\n",
    "\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z97Zu1M4CzE"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k2nAgHR4Fs0"
   },
   "outputs": [],
   "source": [
    "import re,json,random\n",
    "file = open('input/imdb_test.text','w')\n",
    "\n",
    "\n",
    "for movie in [m for m in ground_truth.keys()][int(0.5*len(ground_truth)):int(1*len(ground_truth))]:\n",
    "    if movie not in movies_dic: continue\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    #text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    text = re.sub('\\t',' ',text)\n",
    "\n",
    "    row = []\n",
    "    for r in ground_truth[movie]:\n",
    "        rev = re.sub('\\t',' ',review_ids[r])    \n",
    "        rev = re.sub('\\n',' ',rev)\n",
    "        rev = re.sub(' +',' ',rev)\n",
    "        l = [{\"title\" : text}, {\"title\" : rev}]\n",
    "        file.write(json.dumps(l) + '\\n')\n",
    "        \n",
    "    for r in random.sample(review_ids.keys(),800):  \n",
    "        if r not in ground_truth[movie]:\n",
    "            rev = re.sub('\\t',' ',review_ids[r])    \n",
    "            rev = re.sub('\\n',' ',rev)\n",
    "            rev = re.sub(' +',' ',rev)\n",
    "            l = [{\"title\" : text}, {\"title\": rev}]\n",
    "            file.write(json.dumps(l) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaqjEHWYh863",
    "outputId": "f7afdfeb-9416-4040-e692-47efb1b551e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoints’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!mkdir checkpoints/Structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xs0jFDqiMki3"
   },
   "outputs": [],
   "source": [
    "!cp Structured_Beer_lm\\=distilbert_da\\=drop_col_dk\\=None_su\\=False_size\\=None_id\\=0_test.pt checkpoints/Structured/Beer.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLfFN0KA4gN5",
    "outputId": "e0db546c-2cc8-4ab6-820f-e992bc48a7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-19 17:31:47.988907: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py:25: UserWarning: An input tensor was not cuda.\n",
      "  warnings.warn(\"An input tensor was not cuda.\")\n",
      "314777it [56:23, 93.02it/s]\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "!CUDA_VISIBLE_DEVICES=0 python matcher.py \\\n",
    "  --input_path input/imdb_test.text \\\n",
    "  --output_path output/imdb_output.jsonl \\\n",
    "  --lm distilbert \\\n",
    "  --use_gpu \\\n",
    "  --fp16 \\\n",
    "  --checkpoint_path checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIjcHE48iUtu"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "file = open('output/imdb_output.jsonl','r')\n",
    "\n",
    "lines = []\n",
    "for r in file.readlines():\n",
    "  lines.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd9fECAGi0Iv",
    "outputId": "65a3b536-e667-46bf-b674-3b3f7647aab3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [16:43<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "ditto_movie = {}\n",
    "\n",
    "for movie in tqdm([m for m in ground_truth.keys()][int(0.5*len(ground_truth)):int(1*len(ground_truth))],position=0):\n",
    "    if movie not in movies_dic: continue\n",
    "\n",
    "    ditto_movie [movie] = {}\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    #text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    temp = {}\n",
    "    for l in lines:\n",
    "      ll = json.loads(l)\n",
    "\n",
    "      if ll['left']['title'] == text:\n",
    "        rev = ll['right']['title']\n",
    "\n",
    "        if rev not in id_revs: continue\n",
    "    \n",
    "        \n",
    "        if ll['match'] == '0': \n",
    "          score = 1 - ll['match_confidence']\n",
    "        else:\n",
    "          score = ll['match_confidence']\n",
    "\n",
    "        temp[id_revs[rev]] = score\n",
    "      \n",
    "    ditto_movie[movie] = dict(sorted(temp.items(), key=lambda x: x[1],reverse=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyESv2pKQIn2",
    "outputId": "1480a193-cd69-4a39-9306-951c260b9e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################### 1 ###########################\n",
      "\n",
      "MRR: 0.2748091603053435 MAP: 0.13740458015267176 HAS POSITIVE: 0.2748091603053435\n",
      "\n",
      "#################### 5 ###########################\n",
      "\n",
      "MRR: 0.3951229855810008 MAP: 0.2560856658184902 HAS POSITIVE: 0.5852417302798982\n",
      "\n",
      "#################### 20 ###########################\n",
      "\n",
      "MRR: 0.4087062283290392 MAP: 0.2744194164351681 HAS POSITIVE: 0.7201017811704835\n",
      "\n",
      "#################### 50 ###########################\n",
      "\n",
      "MRR: 0.4096140756699799 MAP: 0.2771014828518717 HAS POSITIVE: 0.7480916030534351\n",
      "\n",
      "#################### 5000 ###########################\n",
      "\n",
      "MRR: 0.4110922918151872 MAP: 0.2797954346788578 HAS POSITIVE: 0.9720101781170484\n"
     ]
    }
   ],
   "source": [
    "for KK in [1,5,20,500]: \n",
    "    i = 0\n",
    "    precision,recall,fs = 0,0,0\n",
    "    MAP, MR, hasP = 0,0,0\n",
    "\n",
    "    for movie in ditto_movie:\n",
    "        if movie not in ground_truth: continue\n",
    "        #if row_ids[movie] not in movie_review_d2v: continue\n",
    "        \n",
    "        preds =  [f for (f,j) in   sorted(ditto_movie[movie].items(), key=lambda x: x[1],reverse=True)  ][0:KK]\n",
    "\n",
    "        if len(preds) == 0: continue\n",
    "        golds = [f for f in ground_truth[movie]]\n",
    "        i+=1\n",
    "\n",
    "        MAP += MAP_K(golds,preds)\n",
    "        MR += MRRR(golds,preds)\n",
    "        hasP += HAS_POSITIVE(golds,preds)\n",
    "        \n",
    "    print('\\n#################### ' + str(KK) + ' ###########################\\n')\n",
    "    print('MRR:',MR/i,'MAP:',MAP/i, 'HAS POSITIVE:', hasP/i)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ditto_IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
