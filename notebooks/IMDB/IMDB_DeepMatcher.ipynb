{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:52:14.188494Z",
     "start_time": "2021-07-23T10:52:11.306901Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from graphUtils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uz9q8lpW8FLd"
   },
   "source": [
    "# DeepMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o27j_TS68BQj",
    "outputId": "1c85931d-9ac8-4098-d159-e334f506457d"
   },
   "outputs": [],
   "source": [
    "!pip install deepmatcher "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj0jduYJCKMY"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:51:39.972818Z",
     "start_time": "2021-07-23T10:51:39.922567Z"
    },
    "id": "t9fwou5a_olC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df = pickle.load(open('../../data/imdb/imdb_reviews_1000film.df','rb'))\n",
    "ground_truth = pickle.load(open('../../data/imdb/imdb_GT.pkl','rb'))\n",
    "review_ids = pickle.load(open('../../data/imdb/imdb_reviewIDs.pkl','rb'))\n",
    "row_ids = pickle.load(open('../../data/imdb/imdb_movieIDs.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T10:51:56.340797Z",
     "start_time": "2021-07-23T10:51:55.815362Z"
    },
    "id": "R2IJFRvD_0Ka"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "movies_dic = {}\n",
    "with open('../../data/imdb/imdb_movielens.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        if row[12].replace('_',' ') not in movies_dic: \n",
    "            movies_dic[row[12].replace('_',' ')] = []\n",
    "            \n",
    "        temp = [r.replace('_',' ') for r in row[0:10]]\n",
    "        \n",
    "        month,year = '',''\n",
    "        if len(row[10]) > 0:        \n",
    "            month = datetime.date(1900, int(row[10][4::]), 1).strftime('%B')\n",
    "            year = row[10][0:4]\n",
    "        \n",
    "        temp.append(month.lower() + ' ' + year)\n",
    "        temp.append(int(float(row[14])))\n",
    "        \n",
    "        movies_dic[row[12].replace('_',' ')].append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwCEDmZ-QSlK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPpQsVnoCPwj"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "header = ['left_movie','right_movie','label']\n",
    "all_table = []\n",
    "\n",
    "for movie in [m for m in ground_truth.keys()][0:int(0.6*len(ground_truth))]:\n",
    "    if movie not in movies_dic: continue\n",
    "    #text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    text = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "\n",
    "    row = []\n",
    "    for r in ground_truth[movie]:\n",
    "        all_table.append([text,review_ids[r],'1'])\n",
    "        \n",
    "    for r in random.sample(review_ids.keys(),len(review_ids)):\n",
    "        if r not in ground_truth[movie]:\n",
    "            all_table.append([text,review_ids[r],'0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayXBZ-w8RBHl",
    "outputId": "09352ed2-7cd7-43e0-fd5d-5cf94f2807c1"
   },
   "outputs": [],
   "source": [
    "len(all_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQdBohhSPpgP"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.DataFrame(all_table,columns=header)\n",
    "df = shuffle(df)\n",
    "train, test, val = train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20P03t2gP3vs"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=False)\n",
    "test.to_csv('test.csv',index=False)\n",
    "val.to_csv('validate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im-bL5Yi8OyW",
    "outputId": "d0d75f20-ed0e-4f67-82a8-672658e7b5f3"
   },
   "outputs": [],
   "source": [
    "import deepmatcher as dm\n",
    "train, validation, test = dm.data.process(\n",
    "    path='',\n",
    "    train='train.csv',\n",
    "    validation='validate.csv',\n",
    "    test='test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHrUjHoB-0Cc",
    "outputId": "68052b2e-cfcd-4126-b402-35c131a04017"
   },
   "outputs": [],
   "source": [
    "model = dm.MatchingModel()\n",
    "model.run_train(train, validation, best_save_path='/deepMatcher_imdb.pth',epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGeJ2L0r_ks9"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjVwpBVT-pjA",
    "outputId": "406d9ff3-3fc4-42c2-988d-a1e244dc3ad7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "header = ['review','left_movie','right_movie','label']\n",
    "#all_table.append(header)\n",
    "deep_imdb = {}\n",
    "for movie in tqdm([m for m in ground_truth.keys()][int(0.5*len(ground_truth))::]):\n",
    "    all_table = []\n",
    "\n",
    "    if movie not in movies_dic: continue\n",
    "    text = ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    t#ext = movie + ' ' + ' '.join(str(m).strip() for m in movies_dic[movie][0] if m not in ['', 'nan'])\n",
    "    \n",
    "    row = []\n",
    "    if movie in ground_truth:\n",
    "        for r in ground_truth[movie]:\n",
    "            all_table.append([r,text,review_ids[r],'1'])\n",
    "        \n",
    "        for r in random.sample(review_ids.keys(),len(review_ids)):\n",
    "            if r not in ground_truth[movie]:\n",
    "                all_table.append([r,text,review_ids[r],'0'])\n",
    "\n",
    "    dff = pd.DataFrame(all_table,columns=header)          \n",
    "    dff = shuffle(dff)\n",
    "    dff[\"id\"] = dff.index\n",
    "\n",
    "    dff.to_csv('new_test.csv',index=False)\n",
    "    rev_index = pd.Series(dff.review.values,index=dff.index).to_dict()    \n",
    "\n",
    "\n",
    "    unlabeled = dm.data.process_unlabeled(path='new_test.csv', trained_model=model,ignore_columns=('label','review'))\n",
    "    preds = model.run_prediction(unlabeled)\n",
    "\n",
    "\n",
    "    temp = {}\n",
    "    for row in preds.iterrows():\n",
    "      temp[rev_index[int(row[0])]] =  float(row[1])\n",
    "      deep_imdb[movie] = temp = dict(sorted(temp.items(), key=lambda x: x[1],reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IXIGy8LexfQg",
    "outputId": "b7585cb6-bad9-4d53-90a1-f7be08368f8e"
   },
   "outputs": [],
   "source": [
    "for KK in [1,5,20,500]: \n",
    "    i = 0\n",
    "    precision,recall,fs = 0,0,0\n",
    "    MAP, MR, hasP = 0,0,0\n",
    "\n",
    "    for movie in deep_imdb:\n",
    "        if movie not in ground_truth: continue\n",
    "        #if row_ids[movie] not in movie_review_d2v: continue\n",
    "        \n",
    "        i+=1\n",
    "        preds =  [f for (f,j) in   sorted(deep_imdb[movie].items(), key=lambda x: x[1],reverse=True)  ][0:KK]\n",
    "        golds = [f for f in ground_truth[movie]]\n",
    "\n",
    "        MAP += MAP_K(golds,preds)\n",
    "        MR += MRRR(golds,preds)\n",
    "        hasP += HAS_POSITIVE(golds,preds)\n",
    "        \n",
    "    print('\\n#################### ' + str(KK) + ' ###########################\\n')\n",
    "    print('MRR:',MR/i,'MAP:',MAP/i, 'HAS POSITIVE:', hasP/i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gVyhOyA8rrp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IMDB_DeepMatcher + Metapath2Vec.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
